{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.2 :: Continuum Analytics, Inc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.1 from d:\\program files (x86)\\anaconda3\\envs\\tf2\\lib\\site-packages\\pip (python 3.6)\n",
      "\n",
      "jupyter core     : 4.6.3\n",
      "jupyter-notebook : 6.0.3\n",
      "qtconsole        : 4.7.3\n",
      "ipython          : 6.1.0\n",
      "ipykernel        : 5.1.4\n",
      "jupyter client   : 6.1.3\n",
      "jupyter lab      : not installed\n",
      "nbconvert        : 5.2.1\n",
      "ipywidgets       : not installed\n",
      "nbformat         : 4.4.0\n",
      "traitlets        : 4.3.2\n",
      "Sklearn verion is 0.19.2\n",
      "Numpy verion is 1.18.4\n",
      "pandas verion is 0.23.4\n",
      "WARNING:tensorflow:From <ipython-input-1-fc11f4b4f1fd>:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "tf version: 2.1.0 \n",
      "use GPU False\n",
      "tf.keras: 2.2.4-tf\n",
      "matplotlib: 3.1.3\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip --version\n",
    "!jupyter --version\n",
    "\n",
    "import sklearn\n",
    "print(\"Sklearn verion is {}\".format(sklearn.__version__))\n",
    "import numpy\n",
    "print(\"Numpy verion is {}\".format(numpy.__version__))\n",
    "import pandas\n",
    "print(\"pandas verion is {}\".format(pandas.__version__))\n",
    "import tensorflow as tf\n",
    "version = tf.__version__\n",
    "gpu_ok = tf.test.is_gpu_available()\n",
    "print(\"tf version:\",version,\"\\nuse GPU\",gpu_ok)\n",
    "print('tf.keras:',tf.keras.__version__)\n",
    "import matplotlib as mat\n",
    "print('matplotlib:',mat.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seaborn: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print('seaborn:',sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Sebastian Raschka & Vahid Mirjalili\" -u -d -v -p numpy,tensorflow,matplotlib,sklearn,pip,notebook,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 和 CPU 切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(gpus, cpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.config.experimental.set_visible_devices(devices=gpus[0:2], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
