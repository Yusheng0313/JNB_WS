{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Introduction to the Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/keras_tuner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called *hyperparameter tuning* or *hypertuning*. \n",
    "\n",
    "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
    "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier\n",
    "\n",
    "In this tutorial, you will use the Keras Tuner to perform hypertuning for an image classification application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IqR2PQG4ZaZ0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g83Lwsy-Aq2_"
   },
   "source": [
    "Install and import the Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_leAIdFKAxAD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReV_UXOgCZvx"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "In this tutorial, you will use the Keras Tuner to find the best hyperparameters for a machine learning model that classifies images of clothing from the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HljH_ENLEdHa"
   },
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/fashion/train-labels-idx1-ubyte.gz\n",
      "./datasets/fashion/train-labels-idx1-ubyte.gz\n",
      "./datasets/fashion/train-labels-idx1-ubyte.gz\n",
      "./datasets/fashion/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 定义加载数据的函数，data_folder为保存gz数据的文件夹，该文件夹下有4个文件\n",
    "# 'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "# 't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "\n",
    "def load_data(data_folder):\n",
    "\n",
    "  files = [\n",
    "      'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "      't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "  ]\n",
    "\n",
    "  paths = []\n",
    "  for fname in files:\n",
    "    paths.append(os.path.join(data_folder,fname))\n",
    "    print(paths[0])\n",
    "\n",
    "  with gzip.open(paths[0], 'rb') as lbpath:\n",
    "    y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[1], 'rb') as imgpath:\n",
    "    x_train = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "\n",
    "  with gzip.open(paths[2], 'rb') as lbpath:\n",
    "    y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[3], 'rb') as imgpath:\n",
    "    x_test = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(img_train, label_train), (img_test, label_test) = load_data('./datasets/fashion/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHlHs9Wj_PUM"
   },
   "outputs": [],
   "source": [
    "#(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLVhXs3xrUD0"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5YEL2H2Ax3e"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a *hypermodel*.\n",
    "\n",
    "You can define a hypermodel through two approaches:\n",
    "\n",
    "* By using a model builder function\n",
    "* By subclassing the `HyperModel` class of the Keras Tuner API\n",
    "\n",
    "You can also use two pre-defined `HyperModel` classes - [HyperXception](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperxception-class) and [HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class) for computer vision applications.\n",
    "\n",
    "In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZQKodC-jtsva"
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "  \n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "  \n",
    "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0J1VYw4q3x0b"
   },
   "source": [
    "## Instantiate the tuner and perform hypertuning\n",
    "\n",
    "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`. In this tutorial, you use the [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) tuner. \n",
    "\n",
    "To instantiate the Hyperband tuner, you must specify the hypermodel, the `objective` to optimize and the maximum number of epochs to train (`max_epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oichQFly6Y46"
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaIhhdKf9VtI"
   },
   "source": [
    "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + log<sub>`factor`</sub>(`max_epochs`) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTeamrUWOJRb"
   },
   "source": [
    "Before running the hyperparameter search, define a callback to clear the training outputs at the end of every training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Bbr_8QE76PJd"
   },
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKghEo15Tduy"
   },
   "source": [
    "Run the hyperparameter search. The arguments for the search method are the same as those used for `tf.keras.model.fit` in addition to the callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSBQcTHF9cKt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c6ccb5ae779391947fa52a8890de6233</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8481000065803528</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 480 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lak_ylf88xBv"
   },
   "source": [
    "To finish this tutorial, retrain the model with the optimal hyperparameters from the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McO82AXOuxXh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53984/60000 [=========================>....] - ETA: 13:36 - loss: 2.3805 - accuracy: 0.062 - ETA: 1:16 - loss: 1.7178 - accuracy: 0.395 - ETA: 45s - loss: 1.3846 - accuracy: 0.5028 - ETA: 34s - loss: 1.2166 - accuracy: 0.569 - ETA: 27s - loss: 1.1006 - accuracy: 0.606 - ETA: 24s - loss: 1.0394 - accuracy: 0.634 - ETA: 21s - loss: 0.9688 - accuracy: 0.662 - ETA: 19s - loss: 0.9261 - accuracy: 0.673 - ETA: 18s - loss: 0.8938 - accuracy: 0.684 - ETA: 17s - loss: 0.8649 - accuracy: 0.694 - ETA: 16s - loss: 0.8448 - accuracy: 0.700 - ETA: 15s - loss: 0.8331 - accuracy: 0.705 - ETA: 15s - loss: 0.8134 - accuracy: 0.713 - ETA: 14s - loss: 0.8067 - accuracy: 0.718 - ETA: 14s - loss: 0.7951 - accuracy: 0.720 - ETA: 14s - loss: 0.7823 - accuracy: 0.725 - ETA: 13s - loss: 0.7711 - accuracy: 0.727 - ETA: 13s - loss: 0.7652 - accuracy: 0.729 - ETA: 13s - loss: 0.7575 - accuracy: 0.732 - ETA: 13s - loss: 0.7490 - accuracy: 0.735 - ETA: 12s - loss: 0.7436 - accuracy: 0.738 - ETA: 12s - loss: 0.7363 - accuracy: 0.741 - ETA: 12s - loss: 0.7280 - accuracy: 0.744 - ETA: 12s - loss: 0.7233 - accuracy: 0.746 - ETA: 11s - loss: 0.7185 - accuracy: 0.748 - ETA: 11s - loss: 0.7134 - accuracy: 0.750 - ETA: 11s - loss: 0.7068 - accuracy: 0.751 - ETA: 11s - loss: 0.7025 - accuracy: 0.752 - ETA: 11s - loss: 0.7035 - accuracy: 0.752 - ETA: 11s - loss: 0.6989 - accuracy: 0.754 - ETA: 11s - loss: 0.6952 - accuracy: 0.756 - ETA: 10s - loss: 0.6910 - accuracy: 0.757 - ETA: 10s - loss: 0.6833 - accuracy: 0.759 - ETA: 10s - loss: 0.6778 - accuracy: 0.761 - ETA: 10s - loss: 0.6712 - accuracy: 0.764 - ETA: 10s - loss: 0.6677 - accuracy: 0.765 - ETA: 10s - loss: 0.6636 - accuracy: 0.766 - ETA: 10s - loss: 0.6602 - accuracy: 0.767 - ETA: 10s - loss: 0.6593 - accuracy: 0.767 - ETA: 10s - loss: 0.6551 - accuracy: 0.769 - ETA: 10s - loss: 0.6497 - accuracy: 0.770 - ETA: 10s - loss: 0.6444 - accuracy: 0.772 - ETA: 10s - loss: 0.6392 - accuracy: 0.774 - ETA: 10s - loss: 0.6345 - accuracy: 0.775 - ETA: 9s - loss: 0.6336 - accuracy: 0.776 - ETA: 9s - loss: 0.6329 - accuracy: 0.77 - ETA: 9s - loss: 0.6311 - accuracy: 0.77 - ETA: 9s - loss: 0.6273 - accuracy: 0.77 - ETA: 9s - loss: 0.6239 - accuracy: 0.77 - ETA: 9s - loss: 0.6210 - accuracy: 0.78 - ETA: 9s - loss: 0.6165 - accuracy: 0.78 - ETA: 9s - loss: 0.6126 - accuracy: 0.78 - ETA: 9s - loss: 0.6094 - accuracy: 0.78 - ETA: 8s - loss: 0.6083 - accuracy: 0.78 - ETA: 8s - loss: 0.6054 - accuracy: 0.78 - ETA: 8s - loss: 0.6069 - accuracy: 0.78 - ETA: 8s - loss: 0.6044 - accuracy: 0.78 - ETA: 8s - loss: 0.6015 - accuracy: 0.78 - ETA: 8s - loss: 0.5982 - accuracy: 0.79 - ETA: 8s - loss: 0.5957 - accuracy: 0.79 - ETA: 8s - loss: 0.5944 - accuracy: 0.79 - ETA: 8s - loss: 0.5921 - accuracy: 0.79 - ETA: 8s - loss: 0.5906 - accuracy: 0.79 - ETA: 7s - loss: 0.5894 - accuracy: 0.79 - ETA: 7s - loss: 0.5871 - accuracy: 0.79 - ETA: 7s - loss: 0.5850 - accuracy: 0.79 - ETA: 7s - loss: 0.5851 - accuracy: 0.79 - ETA: 7s - loss: 0.5820 - accuracy: 0.79 - ETA: 7s - loss: 0.5805 - accuracy: 0.79 - ETA: 7s - loss: 0.5789 - accuracy: 0.79 - ETA: 7s - loss: 0.5766 - accuracy: 0.79 - ETA: 7s - loss: 0.5751 - accuracy: 0.79 - ETA: 7s - loss: 0.5735 - accuracy: 0.79 - ETA: 7s - loss: 0.5724 - accuracy: 0.79 - ETA: 7s - loss: 0.5710 - accuracy: 0.79 - ETA: 7s - loss: 0.5695 - accuracy: 0.79 - ETA: 7s - loss: 0.5671 - accuracy: 0.80 - ETA: 7s - loss: 0.5652 - accuracy: 0.80 - ETA: 6s - loss: 0.5643 - accuracy: 0.80 - ETA: 6s - loss: 0.5621 - accuracy: 0.80 - ETA: 6s - loss: 0.5627 - accuracy: 0.80 - ETA: 6s - loss: 0.5620 - accuracy: 0.80 - ETA: 6s - loss: 0.5602 - accuracy: 0.80 - ETA: 6s - loss: 0.5592 - accuracy: 0.80 - ETA: 6s - loss: 0.5590 - accuracy: 0.80 - ETA: 6s - loss: 0.5573 - accuracy: 0.80 - ETA: 6s - loss: 0.5558 - accuracy: 0.80 - ETA: 6s - loss: 0.5546 - accuracy: 0.80 - ETA: 6s - loss: 0.5537 - accuracy: 0.80 - ETA: 6s - loss: 0.5523 - accuracy: 0.80 - ETA: 6s - loss: 0.5508 - accuracy: 0.80 - ETA: 6s - loss: 0.5499 - accuracy: 0.80 - ETA: 5s - loss: 0.5486 - accuracy: 0.80 - ETA: 5s - loss: 0.5468 - accuracy: 0.80 - ETA: 5s - loss: 0.5451 - accuracy: 0.80 - ETA: 5s - loss: 0.5440 - accuracy: 0.80 - ETA: 5s - loss: 0.5435 - accuracy: 0.80 - ETA: 5s - loss: 0.5427 - accuracy: 0.80 - ETA: 5s - loss: 0.5415 - accuracy: 0.80 - ETA: 5s - loss: 0.5400 - accuracy: 0.80 - ETA: 5s - loss: 0.5386 - accuracy: 0.80 - ETA: 5s - loss: 0.5375 - accuracy: 0.81 - ETA: 5s - loss: 0.5367 - accuracy: 0.81 - ETA: 5s - loss: 0.5359 - accuracy: 0.81 - ETA: 5s - loss: 0.5351 - accuracy: 0.81 - ETA: 5s - loss: 0.5347 - accuracy: 0.81 - ETA: 5s - loss: 0.5343 - accuracy: 0.81 - ETA: 5s - loss: 0.5331 - accuracy: 0.81 - ETA: 5s - loss: 0.5326 - accuracy: 0.81 - ETA: 5s - loss: 0.5307 - accuracy: 0.81 - ETA: 4s - loss: 0.5300 - accuracy: 0.81 - ETA: 4s - loss: 0.5289 - accuracy: 0.81 - ETA: 4s - loss: 0.5272 - accuracy: 0.81 - ETA: 4s - loss: 0.5264 - accuracy: 0.81 - ETA: 4s - loss: 0.5252 - accuracy: 0.81 - ETA: 4s - loss: 0.5238 - accuracy: 0.81 - ETA: 4s - loss: 0.5231 - accuracy: 0.81 - ETA: 4s - loss: 0.5229 - accuracy: 0.81 - ETA: 4s - loss: 0.5222 - accuracy: 0.81 - ETA: 4s - loss: 0.5211 - accuracy: 0.81 - ETA: 4s - loss: 0.5205 - accuracy: 0.81 - ETA: 4s - loss: 0.5195 - accuracy: 0.81 - ETA: 4s - loss: 0.5186 - accuracy: 0.81 - ETA: 4s - loss: 0.5180 - accuracy: 0.81 - ETA: 4s - loss: 0.5181 - accuracy: 0.81 - ETA: 4s - loss: 0.5175 - accuracy: 0.81 - ETA: 4s - loss: 0.5172 - accuracy: 0.81 - ETA: 4s - loss: 0.5170 - accuracy: 0.81 - ETA: 4s - loss: 0.5164 - accuracy: 0.81 - ETA: 4s - loss: 0.5167 - accuracy: 0.81 - ETA: 4s - loss: 0.5155 - accuracy: 0.81 - ETA: 4s - loss: 0.5150 - accuracy: 0.81 - ETA: 3s - loss: 0.5137 - accuracy: 0.81 - ETA: 3s - loss: 0.5133 - accuracy: 0.81 - ETA: 3s - loss: 0.5127 - accuracy: 0.81 - ETA: 3s - loss: 0.5118 - accuracy: 0.81 - ETA: 3s - loss: 0.5111 - accuracy: 0.81 - ETA: 3s - loss: 0.5108 - accuracy: 0.81 - ETA: 3s - loss: 0.5094 - accuracy: 0.81 - ETA: 3s - loss: 0.5089 - accuracy: 0.81 - ETA: 3s - loss: 0.5079 - accuracy: 0.81 - ETA: 3s - loss: 0.5065 - accuracy: 0.81 - ETA: 3s - loss: 0.5054 - accuracy: 0.82 - ETA: 3s - loss: 0.5046 - accuracy: 0.82 - ETA: 3s - loss: 0.5042 - accuracy: 0.82 - ETA: 3s - loss: 0.5032 - accuracy: 0.82 - ETA: 3s - loss: 0.5031 - accuracy: 0.82 - ETA: 3s - loss: 0.5029 - accuracy: 0.82 - ETA: 3s - loss: 0.5033 - accuracy: 0.82 - ETA: 3s - loss: 0.5033 - accuracy: 0.82 - ETA: 3s - loss: 0.5034 - accuracy: 0.82 - ETA: 3s - loss: 0.5033 - accuracy: 0.82 - ETA: 3s - loss: 0.5033 - accuracy: 0.82 - ETA: 3s - loss: 0.5026 - accuracy: 0.82 - ETA: 3s - loss: 0.5017 - accuracy: 0.82 - ETA: 2s - loss: 0.5014 - accuracy: 0.82 - ETA: 2s - loss: 0.5012 - accuracy: 0.82 - ETA: 2s - loss: 0.5008 - accuracy: 0.82 - ETA: 2s - loss: 0.4999 - accuracy: 0.82 - ETA: 2s - loss: 0.4993 - accuracy: 0.82 - ETA: 2s - loss: 0.4992 - accuracy: 0.82 - ETA: 2s - loss: 0.4983 - accuracy: 0.82 - ETA: 2s - loss: 0.4974 - accuracy: 0.82 - ETA: 2s - loss: 0.4973 - accuracy: 0.82 - ETA: 2s - loss: 0.4968 - accuracy: 0.82 - ETA: 2s - loss: 0.4968 - accuracy: 0.82 - ETA: 2s - loss: 0.4958 - accuracy: 0.82 - ETA: 2s - loss: 0.4956 - accuracy: 0.82 - ETA: 2s - loss: 0.4950 - accuracy: 0.82 - ETA: 2s - loss: 0.4945 - accuracy: 0.82 - ETA: 2s - loss: 0.4941 - accuracy: 0.82 - ETA: 2s - loss: 0.4932 - accuracy: 0.82 - ETA: 2s - loss: 0.4927 - accuracy: 0.82 - ETA: 2s - loss: 0.4919 - accuracy: 0.82 - ETA: 2s - loss: 0.4911 - accuracy: 0.82 - ETA: 2s - loss: 0.4906 - accuracy: 0.82 - ETA: 1s - loss: 0.4903 - accuracy: 0.82 - ETA: 1s - loss: 0.4895 - accuracy: 0.82 - ETA: 1s - loss: 0.4892 - accuracy: 0.82 - ETA: 1s - loss: 0.4891 - accuracy: 0.82 - ETA: 1s - loss: 0.4887 - accuracy: 0.82 - ETA: 1s - loss: 0.4882 - accuracy: 0.82 - ETA: 1s - loss: 0.4876 - accuracy: 0.82 - ETA: 1s - loss: 0.4872 - accuracy: 0.82 - ETA: 1s - loss: 0.4865 - accuracy: 0.82 - ETA: 1s - loss: 0.4855 - accuracy: 0.82 - ETA: 1s - loss: 0.4847 - accuracy: 0.82 - ETA: 1s - loss: 0.4838 - accuracy: 0.82 - ETA: 1s - loss: 0.4828 - accuracy: 0.82 - ETA: 1s - loss: 0.4820 - accuracy: 0.82 - ETA: 1s - loss: 0.4813 - accuracy: 0.8281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 1s - loss: 0.4809 - accuracy: 0.82 - ETA: 1s - loss: 0.4805 - accuracy: 0.82 - ETA: 0s - loss: 0.4796 - accuracy: 0.82 - ETA: 0s - loss: 0.4792 - accuracy: 0.82 - ETA: 0s - loss: 0.4786 - accuracy: 0.82 - ETA: 0s - loss: 0.4781 - accuracy: 0.82 - ETA: 0s - loss: 0.4777 - accuracy: 0.82 - ETA: 0s - loss: 0.4772 - accuracy: 0.82 - ETA: 0s - loss: 0.4765 - accuracy: 0.82 - ETA: 0s - loss: 0.4756 - accuracy: 0.83 - ETA: 0s - loss: 0.4758 - accuracy: 0.82 - ETA: 0s - loss: 0.4753 - accuracy: 0.82 - ETA: 0s - loss: 0.4749 - accuracy: 0.83 - ETA: 0s - loss: 0.4744 - accuracy: 0.83 - ETA: 0s - loss: 0.4742 - accuracy: 0.83 - ETA: 0s - loss: 0.4736 - accuracy: 0.83 - ETA: 0s - loss: 0.4731 - accuracy: 0.83 - ETA: 0s - loss: 0.4729 - accuracy: 0.83 - ETA: 0s - loss: 0.4724 - accuracy: 0.83 - 13s 215us/sample - loss: 0.4723 - accuracy: 0.8309 - val_loss: 0.4202 - val_accuracy: 0.8472\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 13s - loss: 0.2998 - accuracy: 0.875 - ETA: 9s - loss: 0.3789 - accuracy: 0.875 - ETA: 9s - loss: 0.3520 - accuracy: 0.87 - ETA: 9s - loss: 0.3553 - accuracy: 0.87 - ETA: 9s - loss: 0.3583 - accuracy: 0.87 - ETA: 9s - loss: 0.3646 - accuracy: 0.86 - ETA: 9s - loss: 0.3547 - accuracy: 0.87 - ETA: 9s - loss: 0.3534 - accuracy: 0.87 - ETA: 9s - loss: 0.3531 - accuracy: 0.87 - ETA: 9s - loss: 0.3631 - accuracy: 0.86 - ETA: 8s - loss: 0.3641 - accuracy: 0.86 - ETA: 8s - loss: 0.3633 - accuracy: 0.86 - ETA: 8s - loss: 0.3611 - accuracy: 0.86 - ETA: 8s - loss: 0.3571 - accuracy: 0.86 - ETA: 8s - loss: 0.3591 - accuracy: 0.86 - ETA: 8s - loss: 0.3602 - accuracy: 0.86 - ETA: 8s - loss: 0.3650 - accuracy: 0.86 - ETA: 8s - loss: 0.3641 - accuracy: 0.86 - ETA: 8s - loss: 0.3629 - accuracy: 0.86 - ETA: 8s - loss: 0.3627 - accuracy: 0.86 - ETA: 8s - loss: 0.3638 - accuracy: 0.86 - ETA: 8s - loss: 0.3711 - accuracy: 0.85 - ETA: 8s - loss: 0.3713 - accuracy: 0.86 - ETA: 8s - loss: 0.3736 - accuracy: 0.85 - ETA: 7s - loss: 0.3729 - accuracy: 0.85 - ETA: 7s - loss: 0.3719 - accuracy: 0.86 - ETA: 7s - loss: 0.3706 - accuracy: 0.86 - ETA: 7s - loss: 0.3692 - accuracy: 0.86 - ETA: 7s - loss: 0.3703 - accuracy: 0.86 - ETA: 7s - loss: 0.3712 - accuracy: 0.86 - ETA: 7s - loss: 0.3726 - accuracy: 0.86 - ETA: 7s - loss: 0.3733 - accuracy: 0.86 - ETA: 7s - loss: 0.3697 - accuracy: 0.86 - ETA: 7s - loss: 0.3694 - accuracy: 0.86 - ETA: 7s - loss: 0.3691 - accuracy: 0.86 - ETA: 7s - loss: 0.3682 - accuracy: 0.86 - ETA: 7s - loss: 0.3667 - accuracy: 0.86 - ETA: 7s - loss: 0.3658 - accuracy: 0.86 - ETA: 7s - loss: 0.3652 - accuracy: 0.86 - ETA: 7s - loss: 0.3649 - accuracy: 0.86 - ETA: 7s - loss: 0.3653 - accuracy: 0.86 - ETA: 7s - loss: 0.3655 - accuracy: 0.86 - ETA: 7s - loss: 0.3647 - accuracy: 0.86 - ETA: 7s - loss: 0.3647 - accuracy: 0.86 - ETA: 7s - loss: 0.3639 - accuracy: 0.86 - ETA: 6s - loss: 0.3634 - accuracy: 0.86 - ETA: 6s - loss: 0.3633 - accuracy: 0.86 - ETA: 6s - loss: 0.3630 - accuracy: 0.86 - ETA: 6s - loss: 0.3620 - accuracy: 0.86 - ETA: 6s - loss: 0.3621 - accuracy: 0.86 - ETA: 6s - loss: 0.3638 - accuracy: 0.86 - ETA: 6s - loss: 0.3654 - accuracy: 0.86 - ETA: 6s - loss: 0.3633 - accuracy: 0.86 - ETA: 6s - loss: 0.3619 - accuracy: 0.86 - ETA: 6s - loss: 0.3625 - accuracy: 0.86 - ETA: 6s - loss: 0.3621 - accuracy: 0.86 - ETA: 6s - loss: 0.3628 - accuracy: 0.86 - ETA: 6s - loss: 0.3631 - accuracy: 0.86 - ETA: 6s - loss: 0.3628 - accuracy: 0.86 - ETA: 6s - loss: 0.3630 - accuracy: 0.86 - ETA: 6s - loss: 0.3640 - accuracy: 0.86 - ETA: 6s - loss: 0.3645 - accuracy: 0.86 - ETA: 6s - loss: 0.3653 - accuracy: 0.86 - ETA: 6s - loss: 0.3645 - accuracy: 0.86 - ETA: 5s - loss: 0.3631 - accuracy: 0.86 - ETA: 5s - loss: 0.3633 - accuracy: 0.86 - ETA: 5s - loss: 0.3655 - accuracy: 0.86 - ETA: 5s - loss: 0.3651 - accuracy: 0.86 - ETA: 5s - loss: 0.3651 - accuracy: 0.86 - ETA: 5s - loss: 0.3648 - accuracy: 0.86 - ETA: 5s - loss: 0.3640 - accuracy: 0.86 - ETA: 5s - loss: 0.3638 - accuracy: 0.86 - ETA: 5s - loss: 0.3639 - accuracy: 0.86 - ETA: 5s - loss: 0.3648 - accuracy: 0.86 - ETA: 5s - loss: 0.3654 - accuracy: 0.86 - ETA: 5s - loss: 0.3654 - accuracy: 0.86 - ETA: 5s - loss: 0.3652 - accuracy: 0.86 - ETA: 5s - loss: 0.3649 - accuracy: 0.86 - ETA: 5s - loss: 0.3642 - accuracy: 0.86 - ETA: 5s - loss: 0.3637 - accuracy: 0.86 - ETA: 5s - loss: 0.3624 - accuracy: 0.86 - ETA: 5s - loss: 0.3627 - accuracy: 0.86 - ETA: 5s - loss: 0.3621 - accuracy: 0.86 - ETA: 5s - loss: 0.3619 - accuracy: 0.86 - ETA: 4s - loss: 0.3619 - accuracy: 0.86 - ETA: 4s - loss: 0.3622 - accuracy: 0.86 - ETA: 4s - loss: 0.3621 - accuracy: 0.86 - ETA: 4s - loss: 0.3617 - accuracy: 0.86 - ETA: 4s - loss: 0.3614 - accuracy: 0.86 - ETA: 4s - loss: 0.3618 - accuracy: 0.86 - ETA: 4s - loss: 0.3621 - accuracy: 0.86 - ETA: 4s - loss: 0.3623 - accuracy: 0.86 - ETA: 4s - loss: 0.3624 - accuracy: 0.86 - ETA: 4s - loss: 0.3629 - accuracy: 0.86 - ETA: 4s - loss: 0.3632 - accuracy: 0.86 - ETA: 4s - loss: 0.3626 - accuracy: 0.86 - ETA: 4s - loss: 0.3627 - accuracy: 0.86 - ETA: 4s - loss: 0.3632 - accuracy: 0.86 - ETA: 4s - loss: 0.3625 - accuracy: 0.86 - ETA: 4s - loss: 0.3632 - accuracy: 0.86 - ETA: 4s - loss: 0.3620 - accuracy: 0.86 - ETA: 4s - loss: 0.3622 - accuracy: 0.86 - ETA: 3s - loss: 0.3618 - accuracy: 0.86 - ETA: 3s - loss: 0.3626 - accuracy: 0.86 - ETA: 3s - loss: 0.3623 - accuracy: 0.86 - ETA: 3s - loss: 0.3619 - accuracy: 0.86 - ETA: 3s - loss: 0.3624 - accuracy: 0.86 - ETA: 3s - loss: 0.3625 - accuracy: 0.86 - ETA: 3s - loss: 0.3629 - accuracy: 0.86 - ETA: 3s - loss: 0.3627 - accuracy: 0.86 - ETA: 3s - loss: 0.3632 - accuracy: 0.86 - ETA: 3s - loss: 0.3629 - accuracy: 0.86 - ETA: 3s - loss: 0.3631 - accuracy: 0.86 - ETA: 3s - loss: 0.3628 - accuracy: 0.86 - ETA: 3s - loss: 0.3622 - accuracy: 0.86 - ETA: 3s - loss: 0.3619 - accuracy: 0.86 - ETA: 3s - loss: 0.3614 - accuracy: 0.86 - ETA: 3s - loss: 0.3612 - accuracy: 0.86 - ETA: 3s - loss: 0.3611 - accuracy: 0.86 - ETA: 3s - loss: 0.3608 - accuracy: 0.86 - ETA: 3s - loss: 0.3612 - accuracy: 0.86 - ETA: 3s - loss: 0.3609 - accuracy: 0.86 - ETA: 2s - loss: 0.3607 - accuracy: 0.86 - ETA: 2s - loss: 0.3606 - accuracy: 0.86 - ETA: 2s - loss: 0.3609 - accuracy: 0.86 - ETA: 2s - loss: 0.3611 - accuracy: 0.86 - ETA: 2s - loss: 0.3609 - accuracy: 0.86 - ETA: 2s - loss: 0.3609 - accuracy: 0.86 - ETA: 2s - loss: 0.3611 - accuracy: 0.86 - ETA: 2s - loss: 0.3613 - accuracy: 0.86 - ETA: 2s - loss: 0.3611 - accuracy: 0.86 - ETA: 2s - loss: 0.3605 - accuracy: 0.86 - ETA: 2s - loss: 0.3604 - accuracy: 0.86 - ETA: 2s - loss: 0.3601 - accuracy: 0.86 - ETA: 2s - loss: 0.3599 - accuracy: 0.86 - ETA: 2s - loss: 0.3591 - accuracy: 0.86 - ETA: 2s - loss: 0.3589 - accuracy: 0.86 - ETA: 2s - loss: 0.3590 - accuracy: 0.86 - ETA: 2s - loss: 0.3595 - accuracy: 0.86 - ETA: 2s - loss: 0.3591 - accuracy: 0.86 - ETA: 2s - loss: 0.3592 - accuracy: 0.86 - ETA: 1s - loss: 0.3587 - accuracy: 0.86 - ETA: 1s - loss: 0.3583 - accuracy: 0.87 - ETA: 1s - loss: 0.3586 - accuracy: 0.86 - ETA: 1s - loss: 0.3586 - accuracy: 0.86 - ETA: 1s - loss: 0.3586 - accuracy: 0.86 - ETA: 1s - loss: 0.3585 - accuracy: 0.87 - ETA: 1s - loss: 0.3585 - accuracy: 0.87 - ETA: 1s - loss: 0.3582 - accuracy: 0.87 - ETA: 1s - loss: 0.3583 - accuracy: 0.87 - ETA: 1s - loss: 0.3582 - accuracy: 0.87 - ETA: 1s - loss: 0.3582 - accuracy: 0.86 - ETA: 1s - loss: 0.3579 - accuracy: 0.87 - ETA: 1s - loss: 0.3580 - accuracy: 0.87 - ETA: 1s - loss: 0.3582 - accuracy: 0.87 - ETA: 1s - loss: 0.3581 - accuracy: 0.87 - ETA: 1s - loss: 0.3581 - accuracy: 0.87 - ETA: 1s - loss: 0.3578 - accuracy: 0.87 - ETA: 1s - loss: 0.3575 - accuracy: 0.87 - ETA: 1s - loss: 0.3575 - accuracy: 0.87 - ETA: 1s - loss: 0.3571 - accuracy: 0.87 - ETA: 1s - loss: 0.3570 - accuracy: 0.87 - ETA: 1s - loss: 0.3565 - accuracy: 0.87 - ETA: 1s - loss: 0.3568 - accuracy: 0.87 - ETA: 0s - loss: 0.3573 - accuracy: 0.87 - ETA: 0s - loss: 0.3571 - accuracy: 0.87 - ETA: 0s - loss: 0.3571 - accuracy: 0.87 - ETA: 0s - loss: 0.3569 - accuracy: 0.87 - ETA: 0s - loss: 0.3569 - accuracy: 0.87 - ETA: 0s - loss: 0.3573 - accuracy: 0.87 - ETA: 0s - loss: 0.3568 - accuracy: 0.87 - ETA: 0s - loss: 0.3564 - accuracy: 0.87 - ETA: 0s - loss: 0.3563 - accuracy: 0.87 - ETA: 0s - loss: 0.3564 - accuracy: 0.87 - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - ETA: 0s - loss: 0.3558 - accuracy: 0.87 - ETA: 0s - loss: 0.3556 - accuracy: 0.87 - ETA: 0s - loss: 0.3552 - accuracy: 0.87 - ETA: 0s - loss: 0.3558 - accuracy: 0.87 - ETA: 0s - loss: 0.3562 - accuracy: 0.87 - ETA: 0s - loss: 0.3558 - accuracy: 0.87 - ETA: 0s - loss: 0.3558 - accuracy: 0.87 - 11s 183us/sample - loss: 0.3558 - accuracy: 0.8701 - val_loss: 0.3750 - val_accuracy: 0.8639\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57920/60000 [===========================>..] - ETA: 13s - loss: 0.1445 - accuracy: 0.937 - ETA: 10s - loss: 0.3354 - accuracy: 0.884 - ETA: 10s - loss: 0.2984 - accuracy: 0.898 - ETA: 10s - loss: 0.2892 - accuracy: 0.899 - ETA: 9s - loss: 0.3154 - accuracy: 0.887 - ETA: 9s - loss: 0.3098 - accuracy: 0.88 - ETA: 9s - loss: 0.3112 - accuracy: 0.88 - ETA: 9s - loss: 0.3134 - accuracy: 0.88 - ETA: 9s - loss: 0.3218 - accuracy: 0.88 - ETA: 9s - loss: 0.3299 - accuracy: 0.88 - ETA: 10s - loss: 0.3383 - accuracy: 0.876 - ETA: 10s - loss: 0.3336 - accuracy: 0.879 - ETA: 10s - loss: 0.3320 - accuracy: 0.878 - ETA: 10s - loss: 0.3361 - accuracy: 0.877 - ETA: 10s - loss: 0.3390 - accuracy: 0.877 - ETA: 10s - loss: 0.3330 - accuracy: 0.879 - ETA: 10s - loss: 0.3341 - accuracy: 0.878 - ETA: 10s - loss: 0.3327 - accuracy: 0.878 - ETA: 10s - loss: 0.3313 - accuracy: 0.879 - ETA: 10s - loss: 0.3361 - accuracy: 0.875 - ETA: 10s - loss: 0.3343 - accuracy: 0.875 - ETA: 10s - loss: 0.3362 - accuracy: 0.873 - ETA: 10s - loss: 0.3383 - accuracy: 0.872 - ETA: 10s - loss: 0.3366 - accuracy: 0.873 - ETA: 10s - loss: 0.3351 - accuracy: 0.874 - ETA: 10s - loss: 0.3359 - accuracy: 0.873 - ETA: 9s - loss: 0.3343 - accuracy: 0.872 - ETA: 9s - loss: 0.3335 - accuracy: 0.87 - ETA: 9s - loss: 0.3364 - accuracy: 0.87 - ETA: 9s - loss: 0.3338 - accuracy: 0.87 - ETA: 9s - loss: 0.3336 - accuracy: 0.87 - ETA: 9s - loss: 0.3310 - accuracy: 0.87 - ETA: 9s - loss: 0.3293 - accuracy: 0.87 - ETA: 9s - loss: 0.3312 - accuracy: 0.87 - ETA: 9s - loss: 0.3304 - accuracy: 0.87 - ETA: 9s - loss: 0.3320 - accuracy: 0.87 - ETA: 9s - loss: 0.3322 - accuracy: 0.87 - ETA: 9s - loss: 0.3325 - accuracy: 0.87 - ETA: 9s - loss: 0.3337 - accuracy: 0.87 - ETA: 9s - loss: 0.3332 - accuracy: 0.87 - ETA: 9s - loss: 0.3329 - accuracy: 0.87 - ETA: 9s - loss: 0.3345 - accuracy: 0.87 - ETA: 9s - loss: 0.3330 - accuracy: 0.87 - ETA: 9s - loss: 0.3315 - accuracy: 0.87 - ETA: 9s - loss: 0.3316 - accuracy: 0.87 - ETA: 9s - loss: 0.3315 - accuracy: 0.87 - ETA: 9s - loss: 0.3301 - accuracy: 0.87 - ETA: 9s - loss: 0.3290 - accuracy: 0.87 - ETA: 9s - loss: 0.3294 - accuracy: 0.87 - ETA: 8s - loss: 0.3276 - accuracy: 0.87 - ETA: 8s - loss: 0.3277 - accuracy: 0.87 - ETA: 8s - loss: 0.3276 - accuracy: 0.87 - ETA: 8s - loss: 0.3287 - accuracy: 0.87 - ETA: 8s - loss: 0.3290 - accuracy: 0.87 - ETA: 8s - loss: 0.3317 - accuracy: 0.87 - ETA: 8s - loss: 0.3310 - accuracy: 0.87 - ETA: 8s - loss: 0.3313 - accuracy: 0.87 - ETA: 8s - loss: 0.3309 - accuracy: 0.87 - ETA: 8s - loss: 0.3299 - accuracy: 0.87 - ETA: 8s - loss: 0.3290 - accuracy: 0.87 - ETA: 8s - loss: 0.3282 - accuracy: 0.87 - ETA: 8s - loss: 0.3277 - accuracy: 0.87 - ETA: 8s - loss: 0.3270 - accuracy: 0.87 - ETA: 8s - loss: 0.3270 - accuracy: 0.87 - ETA: 8s - loss: 0.3280 - accuracy: 0.87 - ETA: 8s - loss: 0.3272 - accuracy: 0.87 - ETA: 8s - loss: 0.3284 - accuracy: 0.87 - ETA: 8s - loss: 0.3283 - accuracy: 0.87 - ETA: 7s - loss: 0.3284 - accuracy: 0.87 - ETA: 7s - loss: 0.3282 - accuracy: 0.87 - ETA: 7s - loss: 0.3283 - accuracy: 0.87 - ETA: 7s - loss: 0.3289 - accuracy: 0.87 - ETA: 7s - loss: 0.3295 - accuracy: 0.87 - ETA: 7s - loss: 0.3298 - accuracy: 0.87 - ETA: 7s - loss: 0.3306 - accuracy: 0.87 - ETA: 7s - loss: 0.3304 - accuracy: 0.87 - ETA: 7s - loss: 0.3301 - accuracy: 0.87 - ETA: 7s - loss: 0.3301 - accuracy: 0.87 - ETA: 7s - loss: 0.3297 - accuracy: 0.87 - ETA: 7s - loss: 0.3289 - accuracy: 0.87 - ETA: 7s - loss: 0.3285 - accuracy: 0.87 - ETA: 7s - loss: 0.3282 - accuracy: 0.87 - ETA: 7s - loss: 0.3288 - accuracy: 0.87 - ETA: 7s - loss: 0.3272 - accuracy: 0.88 - ETA: 7s - loss: 0.3274 - accuracy: 0.87 - ETA: 6s - loss: 0.3272 - accuracy: 0.87 - ETA: 6s - loss: 0.3274 - accuracy: 0.87 - ETA: 6s - loss: 0.3269 - accuracy: 0.87 - ETA: 6s - loss: 0.3262 - accuracy: 0.88 - ETA: 6s - loss: 0.3250 - accuracy: 0.88 - ETA: 6s - loss: 0.3250 - accuracy: 0.88 - ETA: 6s - loss: 0.3255 - accuracy: 0.88 - ETA: 6s - loss: 0.3257 - accuracy: 0.88 - ETA: 6s - loss: 0.3259 - accuracy: 0.88 - ETA: 6s - loss: 0.3254 - accuracy: 0.88 - ETA: 6s - loss: 0.3253 - accuracy: 0.88 - ETA: 6s - loss: 0.3258 - accuracy: 0.88 - ETA: 6s - loss: 0.3257 - accuracy: 0.88 - ETA: 6s - loss: 0.3260 - accuracy: 0.88 - ETA: 6s - loss: 0.3263 - accuracy: 0.88 - ETA: 6s - loss: 0.3257 - accuracy: 0.88 - ETA: 6s - loss: 0.3257 - accuracy: 0.88 - ETA: 6s - loss: 0.3253 - accuracy: 0.88 - ETA: 6s - loss: 0.3248 - accuracy: 0.88 - ETA: 5s - loss: 0.3250 - accuracy: 0.88 - ETA: 5s - loss: 0.3249 - accuracy: 0.88 - ETA: 5s - loss: 0.3250 - accuracy: 0.88 - ETA: 5s - loss: 0.3237 - accuracy: 0.88 - ETA: 5s - loss: 0.3231 - accuracy: 0.88 - ETA: 5s - loss: 0.3229 - accuracy: 0.88 - ETA: 5s - loss: 0.3226 - accuracy: 0.88 - ETA: 5s - loss: 0.3234 - accuracy: 0.88 - ETA: 5s - loss: 0.3239 - accuracy: 0.88 - ETA: 5s - loss: 0.3245 - accuracy: 0.88 - ETA: 5s - loss: 0.3251 - accuracy: 0.88 - ETA: 5s - loss: 0.3256 - accuracy: 0.88 - ETA: 5s - loss: 0.3254 - accuracy: 0.88 - ETA: 5s - loss: 0.3251 - accuracy: 0.88 - ETA: 5s - loss: 0.3248 - accuracy: 0.88 - ETA: 5s - loss: 0.3247 - accuracy: 0.88 - ETA: 4s - loss: 0.3248 - accuracy: 0.88 - ETA: 4s - loss: 0.3252 - accuracy: 0.88 - ETA: 4s - loss: 0.3254 - accuracy: 0.88 - ETA: 4s - loss: 0.3251 - accuracy: 0.88 - ETA: 4s - loss: 0.3252 - accuracy: 0.88 - ETA: 4s - loss: 0.3254 - accuracy: 0.88 - ETA: 4s - loss: 0.3249 - accuracy: 0.88 - ETA: 4s - loss: 0.3248 - accuracy: 0.88 - ETA: 4s - loss: 0.3245 - accuracy: 0.88 - ETA: 4s - loss: 0.3240 - accuracy: 0.88 - ETA: 4s - loss: 0.3236 - accuracy: 0.88 - ETA: 4s - loss: 0.3232 - accuracy: 0.88 - ETA: 4s - loss: 0.3235 - accuracy: 0.88 - ETA: 4s - loss: 0.3233 - accuracy: 0.88 - ETA: 4s - loss: 0.3229 - accuracy: 0.88 - ETA: 3s - loss: 0.3226 - accuracy: 0.88 - ETA: 3s - loss: 0.3227 - accuracy: 0.88 - ETA: 3s - loss: 0.3231 - accuracy: 0.88 - ETA: 3s - loss: 0.3229 - accuracy: 0.88 - ETA: 3s - loss: 0.3229 - accuracy: 0.88 - ETA: 3s - loss: 0.3229 - accuracy: 0.88 - ETA: 3s - loss: 0.3224 - accuracy: 0.88 - ETA: 3s - loss: 0.3223 - accuracy: 0.88 - ETA: 3s - loss: 0.3221 - accuracy: 0.88 - ETA: 3s - loss: 0.3224 - accuracy: 0.88 - ETA: 3s - loss: 0.3224 - accuracy: 0.88 - ETA: 3s - loss: 0.3223 - accuracy: 0.88 - ETA: 3s - loss: 0.3223 - accuracy: 0.88 - ETA: 3s - loss: 0.3217 - accuracy: 0.88 - ETA: 2s - loss: 0.3217 - accuracy: 0.88 - ETA: 2s - loss: 0.3217 - accuracy: 0.88 - ETA: 2s - loss: 0.3214 - accuracy: 0.88 - ETA: 2s - loss: 0.3219 - accuracy: 0.88 - ETA: 2s - loss: 0.3224 - accuracy: 0.88 - ETA: 2s - loss: 0.3221 - accuracy: 0.88 - ETA: 2s - loss: 0.3218 - accuracy: 0.88 - ETA: 2s - loss: 0.3216 - accuracy: 0.88 - ETA: 2s - loss: 0.3216 - accuracy: 0.88 - ETA: 2s - loss: 0.3214 - accuracy: 0.88 - ETA: 2s - loss: 0.3219 - accuracy: 0.88 - ETA: 2s - loss: 0.3217 - accuracy: 0.88 - ETA: 2s - loss: 0.3217 - accuracy: 0.88 - ETA: 2s - loss: 0.3219 - accuracy: 0.88 - ETA: 2s - loss: 0.3216 - accuracy: 0.88 - ETA: 2s - loss: 0.3215 - accuracy: 0.88 - ETA: 1s - loss: 0.3212 - accuracy: 0.88 - ETA: 1s - loss: 0.3208 - accuracy: 0.88 - ETA: 1s - loss: 0.3208 - accuracy: 0.88 - ETA: 1s - loss: 0.3204 - accuracy: 0.88 - ETA: 1s - loss: 0.3201 - accuracy: 0.88 - ETA: 1s - loss: 0.3203 - accuracy: 0.88 - ETA: 1s - loss: 0.3204 - accuracy: 0.88 - ETA: 1s - loss: 0.3205 - accuracy: 0.88 - ETA: 1s - loss: 0.3208 - accuracy: 0.88 - ETA: 1s - loss: 0.3209 - accuracy: 0.88 - ETA: 1s - loss: 0.3206 - accuracy: 0.88 - ETA: 1s - loss: 0.3207 - accuracy: 0.88 - ETA: 1s - loss: 0.3206 - accuracy: 0.88 - ETA: 1s - loss: 0.3206 - accuracy: 0.88 - ETA: 1s - loss: 0.3210 - accuracy: 0.88 - ETA: 1s - loss: 0.3206 - accuracy: 0.88 - ETA: 1s - loss: 0.3204 - accuracy: 0.88 - ETA: 0s - loss: 0.3208 - accuracy: 0.88 - ETA: 0s - loss: 0.3209 - accuracy: 0.88 - ETA: 0s - loss: 0.3208 - accuracy: 0.88 - ETA: 0s - loss: 0.3209 - accuracy: 0.88 - ETA: 0s - loss: 0.3206 - accuracy: 0.88 - ETA: 0s - loss: 0.3203 - accuracy: 0.88 - ETA: 0s - loss: 0.3208 - accuracy: 0.88 - ETA: 0s - loss: 0.3208 - accuracy: 0.88 - ETA: 0s - loss: 0.3209 - accuracy: 0.88 - ETA: 0s - loss: 0.3209 - accuracy: 0.88 - ETA: 0s - loss: 0.3210 - accuracy: 0.8822"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.88 - ETA: 0s - loss: 0.3212 - accuracy: 0.88 - ETA: 0s - loss: 0.3214 - accuracy: 0.88 - ETA: 0s - loss: 0.3214 - accuracy: 0.88 - ETA: 0s - loss: 0.3213 - accuracy: 0.88 - ETA: 0s - loss: 0.3214 - accuracy: 0.88 - ETA: 0s - loss: 0.3213 - accuracy: 0.88 - ETA: 0s - loss: 0.3216 - accuracy: 0.88 - ETA: 0s - loss: 0.3216 - accuracy: 0.88 - 12s 199us/sample - loss: 0.3216 - accuracy: 0.8821 - val_loss: 0.3676 - val_accuracy: 0.8688\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58784/60000 [============================>.] - ETA: 13s - loss: 0.2607 - accuracy: 0.875 - ETA: 9s - loss: 0.3816 - accuracy: 0.860 - ETA: 10s - loss: 0.3402 - accuracy: 0.876 - ETA: 10s - loss: 0.3099 - accuracy: 0.885 - ETA: 10s - loss: 0.3031 - accuracy: 0.891 - ETA: 9s - loss: 0.3118 - accuracy: 0.889 - ETA: 9s - loss: 0.3066 - accuracy: 0.88 - ETA: 9s - loss: 0.3009 - accuracy: 0.89 - ETA: 9s - loss: 0.2975 - accuracy: 0.89 - ETA: 9s - loss: 0.3012 - accuracy: 0.89 - ETA: 9s - loss: 0.3013 - accuracy: 0.89 - ETA: 9s - loss: 0.3015 - accuracy: 0.89 - ETA: 9s - loss: 0.3030 - accuracy: 0.89 - ETA: 9s - loss: 0.3009 - accuracy: 0.89 - ETA: 9s - loss: 0.3032 - accuracy: 0.89 - ETA: 9s - loss: 0.3070 - accuracy: 0.88 - ETA: 9s - loss: 0.3086 - accuracy: 0.88 - ETA: 9s - loss: 0.3093 - accuracy: 0.88 - ETA: 9s - loss: 0.3130 - accuracy: 0.88 - ETA: 9s - loss: 0.3132 - accuracy: 0.88 - ETA: 9s - loss: 0.3141 - accuracy: 0.88 - ETA: 9s - loss: 0.3154 - accuracy: 0.88 - ETA: 9s - loss: 0.3141 - accuracy: 0.88 - ETA: 9s - loss: 0.3117 - accuracy: 0.88 - ETA: 9s - loss: 0.3087 - accuracy: 0.88 - ETA: 8s - loss: 0.3083 - accuracy: 0.88 - ETA: 8s - loss: 0.3086 - accuracy: 0.88 - ETA: 8s - loss: 0.3074 - accuracy: 0.88 - ETA: 8s - loss: 0.3088 - accuracy: 0.88 - ETA: 8s - loss: 0.3078 - accuracy: 0.88 - ETA: 8s - loss: 0.3072 - accuracy: 0.88 - ETA: 8s - loss: 0.3084 - accuracy: 0.88 - ETA: 8s - loss: 0.3079 - accuracy: 0.88 - ETA: 8s - loss: 0.3075 - accuracy: 0.88 - ETA: 8s - loss: 0.3058 - accuracy: 0.88 - ETA: 8s - loss: 0.3074 - accuracy: 0.88 - ETA: 8s - loss: 0.3087 - accuracy: 0.88 - ETA: 8s - loss: 0.3086 - accuracy: 0.88 - ETA: 8s - loss: 0.3088 - accuracy: 0.88 - ETA: 8s - loss: 0.3066 - accuracy: 0.88 - ETA: 8s - loss: 0.3072 - accuracy: 0.88 - ETA: 8s - loss: 0.3064 - accuracy: 0.88 - ETA: 8s - loss: 0.3068 - accuracy: 0.88 - ETA: 8s - loss: 0.3059 - accuracy: 0.88 - ETA: 8s - loss: 0.3062 - accuracy: 0.88 - ETA: 8s - loss: 0.3063 - accuracy: 0.88 - ETA: 8s - loss: 0.3063 - accuracy: 0.88 - ETA: 8s - loss: 0.3063 - accuracy: 0.88 - ETA: 8s - loss: 0.3078 - accuracy: 0.88 - ETA: 8s - loss: 0.3088 - accuracy: 0.88 - ETA: 8s - loss: 0.3077 - accuracy: 0.88 - ETA: 8s - loss: 0.3068 - accuracy: 0.88 - ETA: 8s - loss: 0.3067 - accuracy: 0.88 - ETA: 8s - loss: 0.3068 - accuracy: 0.88 - ETA: 8s - loss: 0.3070 - accuracy: 0.88 - ETA: 8s - loss: 0.3070 - accuracy: 0.88 - ETA: 8s - loss: 0.3074 - accuracy: 0.88 - ETA: 7s - loss: 0.3075 - accuracy: 0.88 - ETA: 7s - loss: 0.3067 - accuracy: 0.88 - ETA: 7s - loss: 0.3063 - accuracy: 0.88 - ETA: 7s - loss: 0.3051 - accuracy: 0.88 - ETA: 7s - loss: 0.3052 - accuracy: 0.88 - ETA: 7s - loss: 0.3047 - accuracy: 0.88 - ETA: 7s - loss: 0.3042 - accuracy: 0.88 - ETA: 7s - loss: 0.3048 - accuracy: 0.88 - ETA: 7s - loss: 0.3043 - accuracy: 0.88 - ETA: 7s - loss: 0.3042 - accuracy: 0.88 - ETA: 7s - loss: 0.3036 - accuracy: 0.88 - ETA: 7s - loss: 0.3033 - accuracy: 0.88 - ETA: 7s - loss: 0.3022 - accuracy: 0.88 - ETA: 7s - loss: 0.3019 - accuracy: 0.88 - ETA: 7s - loss: 0.3019 - accuracy: 0.88 - ETA: 7s - loss: 0.3015 - accuracy: 0.88 - ETA: 7s - loss: 0.3012 - accuracy: 0.88 - ETA: 7s - loss: 0.3003 - accuracy: 0.88 - ETA: 7s - loss: 0.3002 - accuracy: 0.88 - ETA: 7s - loss: 0.3006 - accuracy: 0.88 - ETA: 6s - loss: 0.3012 - accuracy: 0.88 - ETA: 6s - loss: 0.3005 - accuracy: 0.88 - ETA: 6s - loss: 0.3004 - accuracy: 0.88 - ETA: 6s - loss: 0.3003 - accuracy: 0.88 - ETA: 6s - loss: 0.3009 - accuracy: 0.88 - ETA: 6s - loss: 0.3016 - accuracy: 0.88 - ETA: 6s - loss: 0.3008 - accuracy: 0.88 - ETA: 6s - loss: 0.3015 - accuracy: 0.88 - ETA: 6s - loss: 0.3009 - accuracy: 0.88 - ETA: 6s - loss: 0.3005 - accuracy: 0.88 - ETA: 6s - loss: 0.2995 - accuracy: 0.88 - ETA: 6s - loss: 0.2999 - accuracy: 0.88 - ETA: 6s - loss: 0.3002 - accuracy: 0.88 - ETA: 6s - loss: 0.2994 - accuracy: 0.88 - ETA: 6s - loss: 0.2992 - accuracy: 0.88 - ETA: 6s - loss: 0.2997 - accuracy: 0.88 - ETA: 6s - loss: 0.2997 - accuracy: 0.88 - ETA: 5s - loss: 0.2991 - accuracy: 0.88 - ETA: 5s - loss: 0.2988 - accuracy: 0.88 - ETA: 5s - loss: 0.2984 - accuracy: 0.88 - ETA: 5s - loss: 0.2975 - accuracy: 0.88 - ETA: 5s - loss: 0.2965 - accuracy: 0.88 - ETA: 5s - loss: 0.2956 - accuracy: 0.88 - ETA: 5s - loss: 0.2955 - accuracy: 0.88 - ETA: 5s - loss: 0.2971 - accuracy: 0.88 - ETA: 5s - loss: 0.2976 - accuracy: 0.88 - ETA: 5s - loss: 0.2973 - accuracy: 0.88 - ETA: 5s - loss: 0.2977 - accuracy: 0.88 - ETA: 5s - loss: 0.2982 - accuracy: 0.88 - ETA: 5s - loss: 0.2976 - accuracy: 0.88 - ETA: 5s - loss: 0.2985 - accuracy: 0.88 - ETA: 5s - loss: 0.2988 - accuracy: 0.88 - ETA: 5s - loss: 0.2982 - accuracy: 0.88 - ETA: 4s - loss: 0.2981 - accuracy: 0.88 - ETA: 4s - loss: 0.2983 - accuracy: 0.88 - ETA: 4s - loss: 0.2980 - accuracy: 0.88 - ETA: 4s - loss: 0.2980 - accuracy: 0.88 - ETA: 4s - loss: 0.2975 - accuracy: 0.88 - ETA: 4s - loss: 0.2977 - accuracy: 0.88 - ETA: 4s - loss: 0.2976 - accuracy: 0.88 - ETA: 4s - loss: 0.2975 - accuracy: 0.88 - ETA: 4s - loss: 0.2975 - accuracy: 0.88 - ETA: 4s - loss: 0.2971 - accuracy: 0.88 - ETA: 4s - loss: 0.2968 - accuracy: 0.88 - ETA: 4s - loss: 0.2962 - accuracy: 0.89 - ETA: 4s - loss: 0.2961 - accuracy: 0.89 - ETA: 4s - loss: 0.2957 - accuracy: 0.89 - ETA: 4s - loss: 0.2957 - accuracy: 0.89 - ETA: 4s - loss: 0.2955 - accuracy: 0.89 - ETA: 4s - loss: 0.2955 - accuracy: 0.89 - ETA: 4s - loss: 0.2952 - accuracy: 0.89 - ETA: 3s - loss: 0.2957 - accuracy: 0.89 - ETA: 3s - loss: 0.2962 - accuracy: 0.88 - ETA: 3s - loss: 0.2964 - accuracy: 0.89 - ETA: 3s - loss: 0.2964 - accuracy: 0.89 - ETA: 3s - loss: 0.2965 - accuracy: 0.89 - ETA: 3s - loss: 0.2964 - accuracy: 0.89 - ETA: 3s - loss: 0.2966 - accuracy: 0.89 - ETA: 3s - loss: 0.2967 - accuracy: 0.89 - ETA: 3s - loss: 0.2966 - accuracy: 0.89 - ETA: 3s - loss: 0.2966 - accuracy: 0.89 - ETA: 3s - loss: 0.2961 - accuracy: 0.89 - ETA: 3s - loss: 0.2967 - accuracy: 0.89 - ETA: 3s - loss: 0.2970 - accuracy: 0.89 - ETA: 3s - loss: 0.2967 - accuracy: 0.89 - ETA: 3s - loss: 0.2964 - accuracy: 0.89 - ETA: 2s - loss: 0.2967 - accuracy: 0.89 - ETA: 2s - loss: 0.2970 - accuracy: 0.89 - ETA: 2s - loss: 0.2971 - accuracy: 0.88 - ETA: 2s - loss: 0.2968 - accuracy: 0.89 - ETA: 2s - loss: 0.2965 - accuracy: 0.89 - ETA: 2s - loss: 0.2963 - accuracy: 0.89 - ETA: 2s - loss: 0.2961 - accuracy: 0.89 - ETA: 2s - loss: 0.2964 - accuracy: 0.89 - ETA: 2s - loss: 0.2967 - accuracy: 0.89 - ETA: 2s - loss: 0.2965 - accuracy: 0.89 - ETA: 2s - loss: 0.2961 - accuracy: 0.89 - ETA: 2s - loss: 0.2956 - accuracy: 0.89 - ETA: 2s - loss: 0.2956 - accuracy: 0.89 - ETA: 2s - loss: 0.2955 - accuracy: 0.89 - ETA: 2s - loss: 0.2956 - accuracy: 0.89 - ETA: 2s - loss: 0.2957 - accuracy: 0.89 - ETA: 2s - loss: 0.2957 - accuracy: 0.89 - ETA: 1s - loss: 0.2955 - accuracy: 0.89 - ETA: 1s - loss: 0.2951 - accuracy: 0.89 - ETA: 1s - loss: 0.2951 - accuracy: 0.89 - ETA: 1s - loss: 0.2950 - accuracy: 0.89 - ETA: 1s - loss: 0.2949 - accuracy: 0.89 - ETA: 1s - loss: 0.2949 - accuracy: 0.89 - ETA: 1s - loss: 0.2954 - accuracy: 0.89 - ETA: 1s - loss: 0.2951 - accuracy: 0.89 - ETA: 1s - loss: 0.2951 - accuracy: 0.89 - ETA: 1s - loss: 0.2956 - accuracy: 0.89 - ETA: 1s - loss: 0.2958 - accuracy: 0.89 - ETA: 1s - loss: 0.2957 - accuracy: 0.89 - ETA: 1s - loss: 0.2961 - accuracy: 0.89 - ETA: 1s - loss: 0.2964 - accuracy: 0.89 - ETA: 1s - loss: 0.2966 - accuracy: 0.89 - ETA: 1s - loss: 0.2968 - accuracy: 0.89 - ETA: 1s - loss: 0.2967 - accuracy: 0.89 - ETA: 1s - loss: 0.2972 - accuracy: 0.89 - ETA: 0s - loss: 0.2974 - accuracy: 0.89 - ETA: 0s - loss: 0.2973 - accuracy: 0.89 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.2973 - accuracy: 0.88 - ETA: 0s - loss: 0.2975 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - ETA: 0s - loss: 0.2979 - accuracy: 0.88 - ETA: 0s - loss: 0.2979 - accuracy: 0.88 - ETA: 0s - loss: 0.2976 - accuracy: 0.88 - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - ETA: 0s - loss: 0.2975 - accuracy: 0.88 - ETA: 0s - loss: 0.2973 - accuracy: 0.8893"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.88 - ETA: 0s - loss: 0.2979 - accuracy: 0.88 - ETA: 0s - loss: 0.2980 - accuracy: 0.88 - 12s 193us/sample - loss: 0.2982 - accuracy: 0.8891 - val_loss: 0.3581 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54944/60000 [==========================>...] - ETA: 11s - loss: 0.2465 - accuracy: 0.875 - ETA: 9s - loss: 0.2826 - accuracy: 0.898 - ETA: 8s - loss: 0.3139 - accuracy: 0.88 - ETA: 8s - loss: 0.2814 - accuracy: 0.89 - ETA: 9s - loss: 0.2756 - accuracy: 0.89 - ETA: 9s - loss: 0.2772 - accuracy: 0.89 - ETA: 9s - loss: 0.2747 - accuracy: 0.90 - ETA: 9s - loss: 0.2718 - accuracy: 0.90 - ETA: 10s - loss: 0.2652 - accuracy: 0.902 - ETA: 10s - loss: 0.2706 - accuracy: 0.899 - ETA: 10s - loss: 0.2673 - accuracy: 0.901 - ETA: 10s - loss: 0.2630 - accuracy: 0.903 - ETA: 10s - loss: 0.2676 - accuracy: 0.901 - ETA: 9s - loss: 0.2675 - accuracy: 0.902 - ETA: 9s - loss: 0.2651 - accuracy: 0.90 - ETA: 9s - loss: 0.2711 - accuracy: 0.90 - ETA: 9s - loss: 0.2701 - accuracy: 0.90 - ETA: 9s - loss: 0.2721 - accuracy: 0.90 - ETA: 9s - loss: 0.2715 - accuracy: 0.90 - ETA: 9s - loss: 0.2726 - accuracy: 0.90 - ETA: 9s - loss: 0.2723 - accuracy: 0.90 - ETA: 9s - loss: 0.2710 - accuracy: 0.90 - ETA: 9s - loss: 0.2700 - accuracy: 0.90 - ETA: 9s - loss: 0.2709 - accuracy: 0.90 - ETA: 9s - loss: 0.2700 - accuracy: 0.90 - ETA: 9s - loss: 0.2725 - accuracy: 0.89 - ETA: 9s - loss: 0.2695 - accuracy: 0.90 - ETA: 9s - loss: 0.2708 - accuracy: 0.90 - ETA: 9s - loss: 0.2712 - accuracy: 0.90 - ETA: 9s - loss: 0.2722 - accuracy: 0.89 - ETA: 9s - loss: 0.2715 - accuracy: 0.89 - ETA: 9s - loss: 0.2732 - accuracy: 0.89 - ETA: 9s - loss: 0.2751 - accuracy: 0.89 - ETA: 9s - loss: 0.2762 - accuracy: 0.89 - ETA: 9s - loss: 0.2751 - accuracy: 0.89 - ETA: 9s - loss: 0.2748 - accuracy: 0.89 - ETA: 9s - loss: 0.2750 - accuracy: 0.89 - ETA: 9s - loss: 0.2736 - accuracy: 0.89 - ETA: 9s - loss: 0.2731 - accuracy: 0.89 - ETA: 9s - loss: 0.2715 - accuracy: 0.89 - ETA: 9s - loss: 0.2720 - accuracy: 0.89 - ETA: 9s - loss: 0.2714 - accuracy: 0.89 - ETA: 9s - loss: 0.2715 - accuracy: 0.89 - ETA: 9s - loss: 0.2725 - accuracy: 0.89 - ETA: 9s - loss: 0.2718 - accuracy: 0.89 - ETA: 9s - loss: 0.2709 - accuracy: 0.89 - ETA: 9s - loss: 0.2705 - accuracy: 0.89 - ETA: 9s - loss: 0.2706 - accuracy: 0.89 - ETA: 9s - loss: 0.2690 - accuracy: 0.89 - ETA: 9s - loss: 0.2696 - accuracy: 0.89 - ETA: 9s - loss: 0.2717 - accuracy: 0.89 - ETA: 9s - loss: 0.2722 - accuracy: 0.89 - ETA: 9s - loss: 0.2731 - accuracy: 0.89 - ETA: 9s - loss: 0.2734 - accuracy: 0.89 - ETA: 9s - loss: 0.2734 - accuracy: 0.89 - ETA: 9s - loss: 0.2738 - accuracy: 0.89 - ETA: 9s - loss: 0.2730 - accuracy: 0.89 - ETA: 9s - loss: 0.2742 - accuracy: 0.89 - ETA: 9s - loss: 0.2762 - accuracy: 0.89 - ETA: 9s - loss: 0.2761 - accuracy: 0.89 - ETA: 9s - loss: 0.2755 - accuracy: 0.89 - ETA: 9s - loss: 0.2745 - accuracy: 0.89 - ETA: 9s - loss: 0.2765 - accuracy: 0.89 - ETA: 9s - loss: 0.2769 - accuracy: 0.89 - ETA: 9s - loss: 0.2772 - accuracy: 0.89 - ETA: 9s - loss: 0.2772 - accuracy: 0.89 - ETA: 9s - loss: 0.2770 - accuracy: 0.89 - ETA: 9s - loss: 0.2774 - accuracy: 0.89 - ETA: 8s - loss: 0.2774 - accuracy: 0.89 - ETA: 8s - loss: 0.2770 - accuracy: 0.89 - ETA: 8s - loss: 0.2781 - accuracy: 0.89 - ETA: 8s - loss: 0.2791 - accuracy: 0.89 - ETA: 8s - loss: 0.2790 - accuracy: 0.89 - ETA: 8s - loss: 0.2791 - accuracy: 0.89 - ETA: 8s - loss: 0.2791 - accuracy: 0.89 - ETA: 8s - loss: 0.2803 - accuracy: 0.89 - ETA: 8s - loss: 0.2798 - accuracy: 0.89 - ETA: 8s - loss: 0.2798 - accuracy: 0.89 - ETA: 8s - loss: 0.2798 - accuracy: 0.89 - ETA: 8s - loss: 0.2793 - accuracy: 0.89 - ETA: 8s - loss: 0.2789 - accuracy: 0.89 - ETA: 8s - loss: 0.2778 - accuracy: 0.89 - ETA: 8s - loss: 0.2772 - accuracy: 0.89 - ETA: 7s - loss: 0.2770 - accuracy: 0.89 - ETA: 7s - loss: 0.2777 - accuracy: 0.89 - ETA: 7s - loss: 0.2774 - accuracy: 0.89 - ETA: 7s - loss: 0.2778 - accuracy: 0.89 - ETA: 7s - loss: 0.2768 - accuracy: 0.89 - ETA: 7s - loss: 0.2773 - accuracy: 0.89 - ETA: 7s - loss: 0.2777 - accuracy: 0.89 - ETA: 7s - loss: 0.2780 - accuracy: 0.89 - ETA: 7s - loss: 0.2780 - accuracy: 0.89 - ETA: 7s - loss: 0.2782 - accuracy: 0.89 - ETA: 7s - loss: 0.2789 - accuracy: 0.89 - ETA: 6s - loss: 0.2788 - accuracy: 0.89 - ETA: 6s - loss: 0.2784 - accuracy: 0.89 - ETA: 6s - loss: 0.2795 - accuracy: 0.89 - ETA: 6s - loss: 0.2786 - accuracy: 0.89 - ETA: 6s - loss: 0.2786 - accuracy: 0.89 - ETA: 6s - loss: 0.2784 - accuracy: 0.89 - ETA: 6s - loss: 0.2780 - accuracy: 0.89 - ETA: 6s - loss: 0.2783 - accuracy: 0.89 - ETA: 6s - loss: 0.2782 - accuracy: 0.89 - ETA: 6s - loss: 0.2781 - accuracy: 0.89 - ETA: 6s - loss: 0.2784 - accuracy: 0.89 - ETA: 6s - loss: 0.2786 - accuracy: 0.89 - ETA: 5s - loss: 0.2792 - accuracy: 0.89 - ETA: 5s - loss: 0.2787 - accuracy: 0.89 - ETA: 5s - loss: 0.2787 - accuracy: 0.89 - ETA: 5s - loss: 0.2785 - accuracy: 0.89 - ETA: 5s - loss: 0.2793 - accuracy: 0.89 - ETA: 5s - loss: 0.2791 - accuracy: 0.89 - ETA: 5s - loss: 0.2790 - accuracy: 0.89 - ETA: 5s - loss: 0.2792 - accuracy: 0.89 - ETA: 5s - loss: 0.2789 - accuracy: 0.89 - ETA: 5s - loss: 0.2785 - accuracy: 0.89 - ETA: 5s - loss: 0.2784 - accuracy: 0.89 - ETA: 5s - loss: 0.2784 - accuracy: 0.89 - ETA: 5s - loss: 0.2788 - accuracy: 0.89 - ETA: 5s - loss: 0.2787 - accuracy: 0.89 - ETA: 4s - loss: 0.2792 - accuracy: 0.89 - ETA: 4s - loss: 0.2792 - accuracy: 0.89 - ETA: 4s - loss: 0.2796 - accuracy: 0.89 - ETA: 4s - loss: 0.2794 - accuracy: 0.89 - ETA: 4s - loss: 0.2792 - accuracy: 0.89 - ETA: 4s - loss: 0.2793 - accuracy: 0.89 - ETA: 4s - loss: 0.2796 - accuracy: 0.89 - ETA: 4s - loss: 0.2797 - accuracy: 0.89 - ETA: 4s - loss: 0.2794 - accuracy: 0.89 - ETA: 4s - loss: 0.2793 - accuracy: 0.89 - ETA: 4s - loss: 0.2790 - accuracy: 0.89 - ETA: 4s - loss: 0.2795 - accuracy: 0.89 - ETA: 4s - loss: 0.2794 - accuracy: 0.89 - ETA: 4s - loss: 0.2791 - accuracy: 0.89 - ETA: 4s - loss: 0.2791 - accuracy: 0.89 - ETA: 4s - loss: 0.2791 - accuracy: 0.89 - ETA: 4s - loss: 0.2793 - accuracy: 0.89 - ETA: 4s - loss: 0.2795 - accuracy: 0.89 - ETA: 4s - loss: 0.2796 - accuracy: 0.89 - ETA: 4s - loss: 0.2794 - accuracy: 0.89 - ETA: 4s - loss: 0.2790 - accuracy: 0.89 - ETA: 4s - loss: 0.2786 - accuracy: 0.89 - ETA: 4s - loss: 0.2787 - accuracy: 0.89 - ETA: 4s - loss: 0.2788 - accuracy: 0.89 - ETA: 3s - loss: 0.2786 - accuracy: 0.89 - ETA: 3s - loss: 0.2788 - accuracy: 0.89 - ETA: 3s - loss: 0.2796 - accuracy: 0.89 - ETA: 3s - loss: 0.2796 - accuracy: 0.89 - ETA: 3s - loss: 0.2797 - accuracy: 0.89 - ETA: 3s - loss: 0.2801 - accuracy: 0.89 - ETA: 3s - loss: 0.2798 - accuracy: 0.89 - ETA: 3s - loss: 0.2796 - accuracy: 0.89 - ETA: 3s - loss: 0.2797 - accuracy: 0.89 - ETA: 3s - loss: 0.2797 - accuracy: 0.89 - ETA: 3s - loss: 0.2798 - accuracy: 0.89 - ETA: 3s - loss: 0.2800 - accuracy: 0.89 - ETA: 3s - loss: 0.2803 - accuracy: 0.89 - ETA: 3s - loss: 0.2803 - accuracy: 0.89 - ETA: 3s - loss: 0.2804 - accuracy: 0.89 - ETA: 3s - loss: 0.2802 - accuracy: 0.89 - ETA: 3s - loss: 0.2810 - accuracy: 0.89 - ETA: 3s - loss: 0.2810 - accuracy: 0.89 - ETA: 2s - loss: 0.2806 - accuracy: 0.89 - ETA: 2s - loss: 0.2812 - accuracy: 0.89 - ETA: 2s - loss: 0.2808 - accuracy: 0.89 - ETA: 2s - loss: 0.2807 - accuracy: 0.89 - ETA: 2s - loss: 0.2803 - accuracy: 0.89 - ETA: 2s - loss: 0.2806 - accuracy: 0.89 - ETA: 2s - loss: 0.2805 - accuracy: 0.89 - ETA: 2s - loss: 0.2801 - accuracy: 0.89 - ETA: 2s - loss: 0.2798 - accuracy: 0.89 - ETA: 2s - loss: 0.2793 - accuracy: 0.89 - ETA: 2s - loss: 0.2794 - accuracy: 0.89 - ETA: 2s - loss: 0.2793 - accuracy: 0.89 - ETA: 2s - loss: 0.2792 - accuracy: 0.89 - ETA: 2s - loss: 0.2793 - accuracy: 0.89 - ETA: 2s - loss: 0.2792 - accuracy: 0.89 - ETA: 1s - loss: 0.2791 - accuracy: 0.89 - ETA: 1s - loss: 0.2786 - accuracy: 0.89 - ETA: 1s - loss: 0.2785 - accuracy: 0.89 - ETA: 1s - loss: 0.2791 - accuracy: 0.89 - ETA: 1s - loss: 0.2794 - accuracy: 0.89 - ETA: 1s - loss: 0.2796 - accuracy: 0.89 - ETA: 1s - loss: 0.2797 - accuracy: 0.89 - ETA: 1s - loss: 0.2800 - accuracy: 0.89 - ETA: 1s - loss: 0.2800 - accuracy: 0.89 - ETA: 1s - loss: 0.2806 - accuracy: 0.89 - ETA: 1s - loss: 0.2803 - accuracy: 0.89 - ETA: 1s - loss: 0.2803 - accuracy: 0.89 - ETA: 1s - loss: 0.2801 - accuracy: 0.89 - ETA: 1s - loss: 0.2800 - accuracy: 0.89 - ETA: 1s - loss: 0.2804 - accuracy: 0.89 - ETA: 1s - loss: 0.2804 - accuracy: 0.89 - ETA: 0s - loss: 0.2801 - accuracy: 0.8955"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.89 - ETA: 0s - loss: 0.2797 - accuracy: 0.89 - ETA: 0s - loss: 0.2799 - accuracy: 0.89 - ETA: 0s - loss: 0.2796 - accuracy: 0.89 - ETA: 0s - loss: 0.2795 - accuracy: 0.89 - ETA: 0s - loss: 0.2794 - accuracy: 0.89 - ETA: 0s - loss: 0.2794 - accuracy: 0.89 - ETA: 0s - loss: 0.2795 - accuracy: 0.89 - ETA: 0s - loss: 0.2798 - accuracy: 0.89 - ETA: 0s - loss: 0.2798 - accuracy: 0.89 - ETA: 0s - loss: 0.2795 - accuracy: 0.89 - ETA: 0s - loss: 0.2792 - accuracy: 0.89 - ETA: 0s - loss: 0.2794 - accuracy: 0.89 - ETA: 0s - loss: 0.2792 - accuracy: 0.89 - 12s 201us/sample - loss: 0.2793 - accuracy: 0.8956 - val_loss: 0.3624 - val_accuracy: 0.8722\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44384/60000 [=====================>........] - ETA: 13s - loss: 0.1352 - accuracy: 0.968 - ETA: 8s - loss: 0.2876 - accuracy: 0.899 - ETA: 9s - loss: 0.2854 - accuracy: 0.89 - ETA: 8s - loss: 0.2871 - accuracy: 0.89 - ETA: 8s - loss: 0.2691 - accuracy: 0.89 - ETA: 8s - loss: 0.2566 - accuracy: 0.90 - ETA: 8s - loss: 0.2542 - accuracy: 0.90 - ETA: 8s - loss: 0.2527 - accuracy: 0.90 - ETA: 8s - loss: 0.2495 - accuracy: 0.90 - ETA: 8s - loss: 0.2528 - accuracy: 0.90 - ETA: 8s - loss: 0.2522 - accuracy: 0.90 - ETA: 8s - loss: 0.2559 - accuracy: 0.90 - ETA: 8s - loss: 0.2595 - accuracy: 0.90 - ETA: 8s - loss: 0.2567 - accuracy: 0.90 - ETA: 8s - loss: 0.2586 - accuracy: 0.90 - ETA: 8s - loss: 0.2552 - accuracy: 0.90 - ETA: 8s - loss: 0.2580 - accuracy: 0.90 - ETA: 8s - loss: 0.2624 - accuracy: 0.90 - ETA: 8s - loss: 0.2629 - accuracy: 0.90 - ETA: 8s - loss: 0.2622 - accuracy: 0.90 - ETA: 8s - loss: 0.2632 - accuracy: 0.90 - ETA: 8s - loss: 0.2609 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2661 - accuracy: 0.90 - ETA: 8s - loss: 0.2672 - accuracy: 0.90 - ETA: 8s - loss: 0.2679 - accuracy: 0.90 - ETA: 7s - loss: 0.2674 - accuracy: 0.90 - ETA: 7s - loss: 0.2691 - accuracy: 0.90 - ETA: 7s - loss: 0.2680 - accuracy: 0.90 - ETA: 7s - loss: 0.2667 - accuracy: 0.90 - ETA: 7s - loss: 0.2656 - accuracy: 0.90 - ETA: 7s - loss: 0.2651 - accuracy: 0.90 - ETA: 7s - loss: 0.2661 - accuracy: 0.90 - ETA: 7s - loss: 0.2655 - accuracy: 0.90 - ETA: 7s - loss: 0.2643 - accuracy: 0.90 - ETA: 7s - loss: 0.2639 - accuracy: 0.90 - ETA: 7s - loss: 0.2631 - accuracy: 0.90 - ETA: 7s - loss: 0.2623 - accuracy: 0.90 - ETA: 7s - loss: 0.2628 - accuracy: 0.90 - ETA: 7s - loss: 0.2631 - accuracy: 0.90 - ETA: 8s - loss: 0.2627 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2629 - accuracy: 0.90 - ETA: 8s - loss: 0.2637 - accuracy: 0.90 - ETA: 8s - loss: 0.2631 - accuracy: 0.90 - ETA: 8s - loss: 0.2642 - accuracy: 0.90 - ETA: 8s - loss: 0.2636 - accuracy: 0.90 - ETA: 8s - loss: 0.2619 - accuracy: 0.90 - ETA: 8s - loss: 0.2609 - accuracy: 0.90 - ETA: 8s - loss: 0.2611 - accuracy: 0.90 - ETA: 7s - loss: 0.2611 - accuracy: 0.90 - ETA: 7s - loss: 0.2601 - accuracy: 0.90 - ETA: 7s - loss: 0.2602 - accuracy: 0.90 - ETA: 7s - loss: 0.2602 - accuracy: 0.90 - ETA: 7s - loss: 0.2607 - accuracy: 0.90 - ETA: 7s - loss: 0.2601 - accuracy: 0.90 - ETA: 7s - loss: 0.2603 - accuracy: 0.90 - ETA: 7s - loss: 0.2620 - accuracy: 0.90 - ETA: 7s - loss: 0.2611 - accuracy: 0.90 - ETA: 8s - loss: 0.2617 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2634 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2630 - accuracy: 0.90 - ETA: 8s - loss: 0.2632 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2632 - accuracy: 0.90 - ETA: 8s - loss: 0.2635 - accuracy: 0.90 - ETA: 8s - loss: 0.2632 - accuracy: 0.90 - ETA: 8s - loss: 0.2636 - accuracy: 0.90 - ETA: 8s - loss: 0.2633 - accuracy: 0.90 - ETA: 8s - loss: 0.2639 - accuracy: 0.90 - ETA: 8s - loss: 0.2645 - accuracy: 0.90 - ETA: 8s - loss: 0.2647 - accuracy: 0.90 - ETA: 8s - loss: 0.2653 - accuracy: 0.90 - ETA: 8s - loss: 0.2654 - accuracy: 0.90 - ETA: 8s - loss: 0.2660 - accuracy: 0.90 - ETA: 8s - loss: 0.2655 - accuracy: 0.90 - ETA: 8s - loss: 0.2651 - accuracy: 0.90 - ETA: 8s - loss: 0.2648 - accuracy: 0.90 - ETA: 8s - loss: 0.2651 - accuracy: 0.90 - ETA: 8s - loss: 0.2654 - accuracy: 0.90 - ETA: 8s - loss: 0.2659 - accuracy: 0.90 - ETA: 8s - loss: 0.2658 - accuracy: 0.90 - ETA: 8s - loss: 0.2659 - accuracy: 0.90 - ETA: 8s - loss: 0.2654 - accuracy: 0.90 - ETA: 8s - loss: 0.2658 - accuracy: 0.90 - ETA: 8s - loss: 0.2661 - accuracy: 0.90 - ETA: 8s - loss: 0.2671 - accuracy: 0.90 - ETA: 8s - loss: 0.2670 - accuracy: 0.90 - ETA: 8s - loss: 0.2671 - accuracy: 0.90 - ETA: 8s - loss: 0.2663 - accuracy: 0.90 - ETA: 8s - loss: 0.2664 - accuracy: 0.90 - ETA: 8s - loss: 0.2664 - accuracy: 0.90 - ETA: 8s - loss: 0.2665 - accuracy: 0.90 - ETA: 8s - loss: 0.2661 - accuracy: 0.90 - ETA: 8s - loss: 0.2661 - accuracy: 0.90 - ETA: 8s - loss: 0.2660 - accuracy: 0.90 - ETA: 8s - loss: 0.2661 - accuracy: 0.90 - ETA: 7s - loss: 0.2658 - accuracy: 0.90 - ETA: 7s - loss: 0.2662 - accuracy: 0.90 - ETA: 7s - loss: 0.2670 - accuracy: 0.90 - ETA: 7s - loss: 0.2670 - accuracy: 0.90 - ETA: 7s - loss: 0.2666 - accuracy: 0.90 - ETA: 7s - loss: 0.2669 - accuracy: 0.90 - ETA: 7s - loss: 0.2668 - accuracy: 0.90 - ETA: 7s - loss: 0.2669 - accuracy: 0.90 - ETA: 7s - loss: 0.2668 - accuracy: 0.90 - ETA: 7s - loss: 0.2666 - accuracy: 0.90 - ETA: 7s - loss: 0.2662 - accuracy: 0.90 - ETA: 7s - loss: 0.2665 - accuracy: 0.90 - ETA: 7s - loss: 0.2662 - accuracy: 0.90 - ETA: 7s - loss: 0.2662 - accuracy: 0.90 - ETA: 7s - loss: 0.2659 - accuracy: 0.90 - ETA: 7s - loss: 0.2659 - accuracy: 0.90 - ETA: 7s - loss: 0.2655 - accuracy: 0.90 - ETA: 7s - loss: 0.2650 - accuracy: 0.90 - ETA: 7s - loss: 0.2645 - accuracy: 0.90 - ETA: 7s - loss: 0.2646 - accuracy: 0.90 - ETA: 7s - loss: 0.2643 - accuracy: 0.90 - ETA: 7s - loss: 0.2639 - accuracy: 0.90 - ETA: 7s - loss: 0.2637 - accuracy: 0.90 - ETA: 7s - loss: 0.2640 - accuracy: 0.90 - ETA: 7s - loss: 0.2638 - accuracy: 0.90 - ETA: 7s - loss: 0.2634 - accuracy: 0.90 - ETA: 7s - loss: 0.2637 - accuracy: 0.90 - ETA: 7s - loss: 0.2632 - accuracy: 0.90 - ETA: 7s - loss: 0.2629 - accuracy: 0.90 - ETA: 7s - loss: 0.2627 - accuracy: 0.90 - ETA: 6s - loss: 0.2628 - accuracy: 0.90 - ETA: 6s - loss: 0.2627 - accuracy: 0.90 - ETA: 6s - loss: 0.2623 - accuracy: 0.90 - ETA: 6s - loss: 0.2620 - accuracy: 0.90 - ETA: 6s - loss: 0.2619 - accuracy: 0.90 - ETA: 6s - loss: 0.2621 - accuracy: 0.90 - ETA: 6s - loss: 0.2617 - accuracy: 0.90 - ETA: 6s - loss: 0.2616 - accuracy: 0.90 - ETA: 6s - loss: 0.2615 - accuracy: 0.90 - ETA: 6s - loss: 0.2615 - accuracy: 0.90 - ETA: 6s - loss: 0.2618 - accuracy: 0.90 - ETA: 6s - loss: 0.2619 - accuracy: 0.90 - ETA: 6s - loss: 0.2624 - accuracy: 0.90 - ETA: 6s - loss: 0.2625 - accuracy: 0.90 - ETA: 6s - loss: 0.2625 - accuracy: 0.90 - ETA: 6s - loss: 0.2630 - accuracy: 0.90 - ETA: 6s - loss: 0.2631 - accuracy: 0.90 - ETA: 6s - loss: 0.2634 - accuracy: 0.90 - ETA: 6s - loss: 0.2633 - accuracy: 0.90 - ETA: 6s - loss: 0.2633 - accuracy: 0.90 - ETA: 6s - loss: 0.2635 - accuracy: 0.90 - ETA: 5s - loss: 0.2635 - accuracy: 0.90 - ETA: 6s - loss: 0.2635 - accuracy: 0.90 - ETA: 6s - loss: 0.2637 - accuracy: 0.90 - ETA: 6s - loss: 0.2638 - accuracy: 0.90 - ETA: 6s - loss: 0.2640 - accuracy: 0.90 - ETA: 5s - loss: 0.2643 - accuracy: 0.90 - ETA: 5s - loss: 0.2643 - accuracy: 0.90 - ETA: 5s - loss: 0.2642 - accuracy: 0.90 - ETA: 5s - loss: 0.2637 - accuracy: 0.90 - ETA: 5s - loss: 0.2640 - accuracy: 0.90 - ETA: 5s - loss: 0.2637 - accuracy: 0.90 - ETA: 5s - loss: 0.2633 - accuracy: 0.90 - ETA: 5s - loss: 0.2630 - accuracy: 0.90 - ETA: 5s - loss: 0.2631 - accuracy: 0.90 - ETA: 5s - loss: 0.2627 - accuracy: 0.90 - ETA: 5s - loss: 0.2629 - accuracy: 0.90 - ETA: 5s - loss: 0.2629 - accuracy: 0.90 - ETA: 5s - loss: 0.2630 - accuracy: 0.90 - ETA: 5s - loss: 0.2630 - accuracy: 0.90 - ETA: 5s - loss: 0.2629 - accuracy: 0.90 - ETA: 5s - loss: 0.2630 - accuracy: 0.90 - ETA: 5s - loss: 0.2630 - accuracy: 0.90 - ETA: 5s - loss: 0.2631 - accuracy: 0.90 - ETA: 5s - loss: 0.2632 - accuracy: 0.90 - ETA: 5s - loss: 0.2632 - accuracy: 0.90 - ETA: 5s - loss: 0.2632 - accuracy: 0.90 - ETA: 5s - loss: 0.2633 - accuracy: 0.90 - ETA: 4s - loss: 0.2635 - accuracy: 0.90 - ETA: 4s - loss: 0.2633 - accuracy: 0.90 - ETA: 4s - loss: 0.2631 - accuracy: 0.90 - ETA: 4s - loss: 0.2630 - accuracy: 0.90 - ETA: 4s - loss: 0.2630 - accuracy: 0.90 - ETA: 4s - loss: 0.2628 - accuracy: 0.90 - ETA: 4s - loss: 0.2629 - accuracy: 0.90 - ETA: 4s - loss: 0.2629 - accuracy: 0.90 - ETA: 4s - loss: 0.2628 - accuracy: 0.90 - ETA: 4s - loss: 0.2627 - accuracy: 0.90 - ETA: 4s - loss: 0.2625 - accuracy: 0.90 - ETA: 4s - loss: 0.2623 - accuracy: 0.90 - ETA: 3s - loss: 0.2620 - accuracy: 0.90 - ETA: 3s - loss: 0.2617 - accuracy: 0.90 - ETA: 3s - loss: 0.2613 - accuracy: 0.90 - ETA: 3s - loss: 0.2610 - accuracy: 0.90 - ETA: 3s - loss: 0.2612 - accuracy: 0.9012"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 3s - loss: 0.2611 - accuracy: 0.90 - ETA: 3s - loss: 0.2609 - accuracy: 0.90 - ETA: 3s - loss: 0.2611 - accuracy: 0.90 - ETA: 3s - loss: 0.2609 - accuracy: 0.90 - ETA: 3s - loss: 0.2607 - accuracy: 0.90 - ETA: 3s - loss: 0.2604 - accuracy: 0.90 - ETA: 3s - loss: 0.2608 - accuracy: 0.90 - ETA: 3s - loss: 0.2611 - accuracy: 0.90 - ETA: 3s - loss: 0.2610 - accuracy: 0.90 - ETA: 3s - loss: 0.2611 - accuracy: 0.90 - ETA: 3s - loss: 0.2610 - accuracy: 0.90 - ETA: 3s - loss: 0.2613 - accuracy: 0.90 - ETA: 3s - loss: 0.2611 - accuracy: 0.90 - ETA: 3s - loss: 0.2612 - accuracy: 0.90 - ETA: 3s - loss: 0.2609 - accuracy: 0.90 - ETA: 2s - loss: 0.2610 - accuracy: 0.90 - ETA: 2s - loss: 0.2611 - accuracy: 0.90 - ETA: 2s - loss: 0.2616 - accuracy: 0.90 - ETA: 2s - loss: 0.2612 - accuracy: 0.90 - ETA: 2s - loss: 0.2612 - accuracy: 0.90 - ETA: 2s - loss: 0.2615 - accuracy: 0.90 - ETA: 2s - loss: 0.2621 - accuracy: 0.90 - ETA: 2s - loss: 0.2623 - accuracy: 0.90 - ETA: 2s - loss: 0.2625 - accuracy: 0.90 - ETA: 2s - loss: 0.2621 - accuracy: 0.90 - ETA: 2s - loss: 0.2619 - accuracy: 0.90 - ETA: 2s - loss: 0.2620 - accuracy: 0.90 - ETA: 2s - loss: 0.2620 - accuracy: 0.90 - ETA: 2s - loss: 0.2620 - accuracy: 0.90 - ETA: 2s - loss: 0.2620 - accuracy: 0.90 - ETA: 2s - loss: 0.2621 - accuracy: 0.90 - ETA: 2s - loss: 0.2622 - accuracy: 0.90 - ETA: 1s - loss: 0.2628 - accuracy: 0.90 - ETA: 1s - loss: 0.2631 - accuracy: 0.90 - ETA: 1s - loss: 0.2633 - accuracy: 0.90 - ETA: 1s - loss: 0.2631 - accuracy: 0.90 - ETA: 1s - loss: 0.2630 - accuracy: 0.90 - ETA: 1s - loss: 0.2631 - accuracy: 0.90 - ETA: 1s - loss: 0.2632 - accuracy: 0.90 - ETA: 1s - loss: 0.2631 - accuracy: 0.90 - ETA: 1s - loss: 0.2630 - accuracy: 0.90 - ETA: 1s - loss: 0.2630 - accuracy: 0.90 - ETA: 1s - loss: 0.2632 - accuracy: 0.90 - ETA: 1s - loss: 0.2637 - accuracy: 0.90 - ETA: 1s - loss: 0.2635 - accuracy: 0.90 - ETA: 1s - loss: 0.2636 - accuracy: 0.90 - ETA: 0s - loss: 0.2641 - accuracy: 0.90 - ETA: 0s - loss: 0.2642 - accuracy: 0.90 - ETA: 0s - loss: 0.2639 - accuracy: 0.90 - ETA: 0s - loss: 0.2637 - accuracy: 0.90 - ETA: 0s - loss: 0.2640 - accuracy: 0.90 - ETA: 0s - loss: 0.2639 - accuracy: 0.90 - ETA: 0s - loss: 0.2644 - accuracy: 0.90 - ETA: 0s - loss: 0.2645 - accuracy: 0.90 - ETA: 0s - loss: 0.2648 - accuracy: 0.90 - ETA: 0s - loss: 0.2650 - accuracy: 0.90 - ETA: 0s - loss: 0.2649 - accuracy: 0.90 - ETA: 0s - loss: 0.2648 - accuracy: 0.90 - ETA: 0s - loss: 0.2647 - accuracy: 0.90 - 15s 248us/sample - loss: 0.2649 - accuracy: 0.9005 - val_loss: 0.3361 - val_accuracy: 0.8776\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57856/60000 [===========================>..] - ETA: 29s - loss: 0.3620 - accuracy: 0.875 - ETA: 16s - loss: 0.2564 - accuracy: 0.886 - ETA: 18s - loss: 0.2927 - accuracy: 0.889 - ETA: 16s - loss: 0.2781 - accuracy: 0.898 - ETA: 14s - loss: 0.2677 - accuracy: 0.900 - ETA: 14s - loss: 0.2833 - accuracy: 0.897 - ETA: 14s - loss: 0.2765 - accuracy: 0.894 - ETA: 14s - loss: 0.2707 - accuracy: 0.895 - ETA: 13s - loss: 0.2682 - accuracy: 0.901 - ETA: 12s - loss: 0.2642 - accuracy: 0.903 - ETA: 11s - loss: 0.2621 - accuracy: 0.903 - ETA: 11s - loss: 0.2571 - accuracy: 0.903 - ETA: 11s - loss: 0.2506 - accuracy: 0.906 - ETA: 11s - loss: 0.2508 - accuracy: 0.905 - ETA: 11s - loss: 0.2496 - accuracy: 0.905 - ETA: 11s - loss: 0.2463 - accuracy: 0.907 - ETA: 11s - loss: 0.2438 - accuracy: 0.909 - ETA: 11s - loss: 0.2443 - accuracy: 0.909 - ETA: 11s - loss: 0.2460 - accuracy: 0.909 - ETA: 11s - loss: 0.2450 - accuracy: 0.909 - ETA: 11s - loss: 0.2459 - accuracy: 0.909 - ETA: 11s - loss: 0.2442 - accuracy: 0.909 - ETA: 11s - loss: 0.2433 - accuracy: 0.910 - ETA: 11s - loss: 0.2423 - accuracy: 0.910 - ETA: 11s - loss: 0.2450 - accuracy: 0.909 - ETA: 10s - loss: 0.2440 - accuracy: 0.909 - ETA: 10s - loss: 0.2473 - accuracy: 0.908 - ETA: 10s - loss: 0.2473 - accuracy: 0.908 - ETA: 10s - loss: 0.2510 - accuracy: 0.906 - ETA: 10s - loss: 0.2497 - accuracy: 0.906 - ETA: 10s - loss: 0.2507 - accuracy: 0.906 - ETA: 10s - loss: 0.2509 - accuracy: 0.906 - ETA: 10s - loss: 0.2494 - accuracy: 0.907 - ETA: 9s - loss: 0.2493 - accuracy: 0.907 - ETA: 9s - loss: 0.2492 - accuracy: 0.90 - ETA: 10s - loss: 0.2491 - accuracy: 0.907 - ETA: 10s - loss: 0.2475 - accuracy: 0.907 - ETA: 10s - loss: 0.2484 - accuracy: 0.907 - ETA: 9s - loss: 0.2489 - accuracy: 0.906 - ETA: 9s - loss: 0.2487 - accuracy: 0.90 - ETA: 9s - loss: 0.2507 - accuracy: 0.90 - ETA: 9s - loss: 0.2501 - accuracy: 0.90 - ETA: 9s - loss: 0.2484 - accuracy: 0.90 - ETA: 9s - loss: 0.2484 - accuracy: 0.90 - ETA: 9s - loss: 0.2481 - accuracy: 0.90 - ETA: 9s - loss: 0.2500 - accuracy: 0.90 - ETA: 9s - loss: 0.2500 - accuracy: 0.90 - ETA: 9s - loss: 0.2501 - accuracy: 0.90 - ETA: 9s - loss: 0.2503 - accuracy: 0.90 - ETA: 9s - loss: 0.2505 - accuracy: 0.90 - ETA: 9s - loss: 0.2508 - accuracy: 0.90 - ETA: 9s - loss: 0.2505 - accuracy: 0.90 - ETA: 9s - loss: 0.2499 - accuracy: 0.90 - ETA: 9s - loss: 0.2498 - accuracy: 0.90 - ETA: 8s - loss: 0.2486 - accuracy: 0.90 - ETA: 8s - loss: 0.2481 - accuracy: 0.90 - ETA: 8s - loss: 0.2477 - accuracy: 0.90 - ETA: 8s - loss: 0.2481 - accuracy: 0.90 - ETA: 8s - loss: 0.2491 - accuracy: 0.90 - ETA: 8s - loss: 0.2498 - accuracy: 0.90 - ETA: 8s - loss: 0.2494 - accuracy: 0.90 - ETA: 8s - loss: 0.2497 - accuracy: 0.90 - ETA: 8s - loss: 0.2509 - accuracy: 0.90 - ETA: 8s - loss: 0.2516 - accuracy: 0.90 - ETA: 8s - loss: 0.2517 - accuracy: 0.90 - ETA: 7s - loss: 0.2511 - accuracy: 0.90 - ETA: 7s - loss: 0.2521 - accuracy: 0.90 - ETA: 7s - loss: 0.2522 - accuracy: 0.90 - ETA: 7s - loss: 0.2526 - accuracy: 0.90 - ETA: 7s - loss: 0.2527 - accuracy: 0.90 - ETA: 7s - loss: 0.2521 - accuracy: 0.90 - ETA: 7s - loss: 0.2520 - accuracy: 0.90 - ETA: 7s - loss: 0.2523 - accuracy: 0.90 - ETA: 7s - loss: 0.2520 - accuracy: 0.90 - ETA: 7s - loss: 0.2517 - accuracy: 0.90 - ETA: 7s - loss: 0.2516 - accuracy: 0.90 - ETA: 7s - loss: 0.2532 - accuracy: 0.90 - ETA: 7s - loss: 0.2529 - accuracy: 0.90 - ETA: 6s - loss: 0.2525 - accuracy: 0.90 - ETA: 6s - loss: 0.2522 - accuracy: 0.90 - ETA: 6s - loss: 0.2522 - accuracy: 0.90 - ETA: 6s - loss: 0.2522 - accuracy: 0.90 - ETA: 6s - loss: 0.2526 - accuracy: 0.90 - ETA: 6s - loss: 0.2533 - accuracy: 0.90 - ETA: 6s - loss: 0.2530 - accuracy: 0.90 - ETA: 6s - loss: 0.2532 - accuracy: 0.90 - ETA: 6s - loss: 0.2540 - accuracy: 0.90 - ETA: 6s - loss: 0.2531 - accuracy: 0.90 - ETA: 6s - loss: 0.2534 - accuracy: 0.90 - ETA: 6s - loss: 0.2532 - accuracy: 0.90 - ETA: 6s - loss: 0.2536 - accuracy: 0.90 - ETA: 5s - loss: 0.2526 - accuracy: 0.90 - ETA: 5s - loss: 0.2527 - accuracy: 0.90 - ETA: 5s - loss: 0.2522 - accuracy: 0.90 - ETA: 5s - loss: 0.2520 - accuracy: 0.90 - ETA: 5s - loss: 0.2516 - accuracy: 0.90 - ETA: 5s - loss: 0.2517 - accuracy: 0.90 - ETA: 5s - loss: 0.2519 - accuracy: 0.90 - ETA: 5s - loss: 0.2522 - accuracy: 0.90 - ETA: 5s - loss: 0.2524 - accuracy: 0.90 - ETA: 5s - loss: 0.2524 - accuracy: 0.90 - ETA: 5s - loss: 0.2533 - accuracy: 0.90 - ETA: 5s - loss: 0.2527 - accuracy: 0.90 - ETA: 5s - loss: 0.2527 - accuracy: 0.90 - ETA: 5s - loss: 0.2524 - accuracy: 0.90 - ETA: 5s - loss: 0.2529 - accuracy: 0.90 - ETA: 5s - loss: 0.2531 - accuracy: 0.90 - ETA: 4s - loss: 0.2526 - accuracy: 0.90 - ETA: 4s - loss: 0.2522 - accuracy: 0.90 - ETA: 4s - loss: 0.2517 - accuracy: 0.90 - ETA: 4s - loss: 0.2514 - accuracy: 0.90 - ETA: 4s - loss: 0.2513 - accuracy: 0.90 - ETA: 4s - loss: 0.2512 - accuracy: 0.90 - ETA: 4s - loss: 0.2516 - accuracy: 0.90 - ETA: 4s - loss: 0.2517 - accuracy: 0.90 - ETA: 4s - loss: 0.2512 - accuracy: 0.90 - ETA: 4s - loss: 0.2512 - accuracy: 0.90 - ETA: 4s - loss: 0.2511 - accuracy: 0.90 - ETA: 4s - loss: 0.2508 - accuracy: 0.90 - ETA: 4s - loss: 0.2514 - accuracy: 0.90 - ETA: 4s - loss: 0.2518 - accuracy: 0.90 - ETA: 4s - loss: 0.2515 - accuracy: 0.90 - ETA: 4s - loss: 0.2516 - accuracy: 0.90 - ETA: 4s - loss: 0.2520 - accuracy: 0.90 - ETA: 4s - loss: 0.2520 - accuracy: 0.90 - ETA: 4s - loss: 0.2524 - accuracy: 0.90 - ETA: 4s - loss: 0.2526 - accuracy: 0.90 - ETA: 4s - loss: 0.2528 - accuracy: 0.90 - ETA: 3s - loss: 0.2526 - accuracy: 0.90 - ETA: 3s - loss: 0.2522 - accuracy: 0.90 - ETA: 3s - loss: 0.2526 - accuracy: 0.90 - ETA: 3s - loss: 0.2520 - accuracy: 0.90 - ETA: 3s - loss: 0.2521 - accuracy: 0.90 - ETA: 3s - loss: 0.2520 - accuracy: 0.90 - ETA: 3s - loss: 0.2518 - accuracy: 0.90 - ETA: 3s - loss: 0.2516 - accuracy: 0.90 - ETA: 3s - loss: 0.2519 - accuracy: 0.90 - ETA: 3s - loss: 0.2521 - accuracy: 0.90 - ETA: 3s - loss: 0.2521 - accuracy: 0.90 - ETA: 3s - loss: 0.2523 - accuracy: 0.90 - ETA: 3s - loss: 0.2522 - accuracy: 0.90 - ETA: 3s - loss: 0.2528 - accuracy: 0.90 - ETA: 3s - loss: 0.2528 - accuracy: 0.90 - ETA: 3s - loss: 0.2530 - accuracy: 0.90 - ETA: 3s - loss: 0.2526 - accuracy: 0.90 - ETA: 2s - loss: 0.2524 - accuracy: 0.90 - ETA: 2s - loss: 0.2525 - accuracy: 0.90 - ETA: 2s - loss: 0.2525 - accuracy: 0.90 - ETA: 2s - loss: 0.2529 - accuracy: 0.90 - ETA: 2s - loss: 0.2533 - accuracy: 0.90 - ETA: 2s - loss: 0.2534 - accuracy: 0.90 - ETA: 2s - loss: 0.2537 - accuracy: 0.90 - ETA: 2s - loss: 0.2537 - accuracy: 0.90 - ETA: 2s - loss: 0.2543 - accuracy: 0.90 - ETA: 2s - loss: 0.2544 - accuracy: 0.90 - ETA: 2s - loss: 0.2545 - accuracy: 0.90 - ETA: 2s - loss: 0.2549 - accuracy: 0.90 - ETA: 2s - loss: 0.2547 - accuracy: 0.90 - ETA: 2s - loss: 0.2546 - accuracy: 0.90 - ETA: 2s - loss: 0.2545 - accuracy: 0.90 - ETA: 2s - loss: 0.2544 - accuracy: 0.90 - ETA: 2s - loss: 0.2545 - accuracy: 0.90 - ETA: 2s - loss: 0.2543 - accuracy: 0.90 - ETA: 2s - loss: 0.2539 - accuracy: 0.90 - ETA: 2s - loss: 0.2539 - accuracy: 0.90 - ETA: 1s - loss: 0.2540 - accuracy: 0.90 - ETA: 1s - loss: 0.2543 - accuracy: 0.90 - ETA: 1s - loss: 0.2549 - accuracy: 0.90 - ETA: 1s - loss: 0.2555 - accuracy: 0.90 - ETA: 1s - loss: 0.2552 - accuracy: 0.90 - ETA: 1s - loss: 0.2553 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2553 - accuracy: 0.90 - ETA: 1s - loss: 0.2553 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2550 - accuracy: 0.90 - ETA: 1s - loss: 0.2551 - accuracy: 0.90 - ETA: 1s - loss: 0.2550 - accuracy: 0.90 - ETA: 1s - loss: 0.2545 - accuracy: 0.90 - ETA: 0s - loss: 0.2542 - accuracy: 0.90 - ETA: 0s - loss: 0.2539 - accuracy: 0.90 - ETA: 0s - loss: 0.2543 - accuracy: 0.90 - ETA: 0s - loss: 0.2542 - accuracy: 0.90 - ETA: 0s - loss: 0.2541 - accuracy: 0.90 - ETA: 0s - loss: 0.2538 - accuracy: 0.90 - ETA: 0s - loss: 0.2544 - accuracy: 0.90 - ETA: 0s - loss: 0.2542 - accuracy: 0.90 - ETA: 0s - loss: 0.2543 - accuracy: 0.90 - ETA: 0s - loss: 0.2541 - accuracy: 0.90 - ETA: 0s - loss: 0.2540 - accuracy: 0.9055"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.90 - ETA: 0s - loss: 0.2538 - accuracy: 0.90 - ETA: 0s - loss: 0.2536 - accuracy: 0.90 - ETA: 0s - loss: 0.2535 - accuracy: 0.90 - ETA: 0s - loss: 0.2531 - accuracy: 0.90 - ETA: 0s - loss: 0.2529 - accuracy: 0.90 - 12s 195us/sample - loss: 0.2528 - accuracy: 0.9061 - val_loss: 0.3347 - val_accuracy: 0.8834\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - ETA: 16s - loss: 0.2404 - accuracy: 0.968 - ETA: 10s - loss: 0.2642 - accuracy: 0.900 - ETA: 10s - loss: 0.2378 - accuracy: 0.917 - ETA: 10s - loss: 0.2514 - accuracy: 0.911 - ETA: 10s - loss: 0.2558 - accuracy: 0.905 - ETA: 10s - loss: 0.2768 - accuracy: 0.899 - ETA: 10s - loss: 0.2791 - accuracy: 0.902 - ETA: 10s - loss: 0.2727 - accuracy: 0.904 - ETA: 10s - loss: 0.2645 - accuracy: 0.906 - ETA: 10s - loss: 0.2612 - accuracy: 0.904 - ETA: 9s - loss: 0.2573 - accuracy: 0.905 - ETA: 9s - loss: 0.2569 - accuracy: 0.90 - ETA: 9s - loss: 0.2529 - accuracy: 0.90 - ETA: 9s - loss: 0.2542 - accuracy: 0.90 - ETA: 9s - loss: 0.2539 - accuracy: 0.90 - ETA: 9s - loss: 0.2539 - accuracy: 0.90 - ETA: 9s - loss: 0.2566 - accuracy: 0.90 - ETA: 9s - loss: 0.2536 - accuracy: 0.90 - ETA: 9s - loss: 0.2518 - accuracy: 0.90 - ETA: 9s - loss: 0.2503 - accuracy: 0.90 - ETA: 9s - loss: 0.2513 - accuracy: 0.90 - ETA: 9s - loss: 0.2483 - accuracy: 0.90 - ETA: 9s - loss: 0.2517 - accuracy: 0.90 - ETA: 9s - loss: 0.2514 - accuracy: 0.90 - ETA: 8s - loss: 0.2487 - accuracy: 0.90 - ETA: 8s - loss: 0.2470 - accuracy: 0.90 - ETA: 8s - loss: 0.2474 - accuracy: 0.90 - ETA: 8s - loss: 0.2454 - accuracy: 0.90 - ETA: 8s - loss: 0.2460 - accuracy: 0.90 - ETA: 8s - loss: 0.2474 - accuracy: 0.90 - ETA: 8s - loss: 0.2472 - accuracy: 0.90 - ETA: 8s - loss: 0.2478 - accuracy: 0.90 - ETA: 8s - loss: 0.2474 - accuracy: 0.90 - ETA: 8s - loss: 0.2465 - accuracy: 0.90 - ETA: 8s - loss: 0.2468 - accuracy: 0.90 - ETA: 7s - loss: 0.2459 - accuracy: 0.90 - ETA: 7s - loss: 0.2446 - accuracy: 0.90 - ETA: 7s - loss: 0.2451 - accuracy: 0.90 - ETA: 7s - loss: 0.2457 - accuracy: 0.90 - ETA: 7s - loss: 0.2475 - accuracy: 0.90 - ETA: 7s - loss: 0.2483 - accuracy: 0.90 - ETA: 7s - loss: 0.2486 - accuracy: 0.90 - ETA: 7s - loss: 0.2493 - accuracy: 0.90 - ETA: 7s - loss: 0.2486 - accuracy: 0.90 - ETA: 7s - loss: 0.2477 - accuracy: 0.90 - ETA: 7s - loss: 0.2481 - accuracy: 0.90 - ETA: 7s - loss: 0.2487 - accuracy: 0.90 - ETA: 7s - loss: 0.2492 - accuracy: 0.90 - ETA: 7s - loss: 0.2491 - accuracy: 0.90 - ETA: 7s - loss: 0.2498 - accuracy: 0.90 - ETA: 7s - loss: 0.2499 - accuracy: 0.90 - ETA: 6s - loss: 0.2486 - accuracy: 0.90 - ETA: 6s - loss: 0.2482 - accuracy: 0.90 - ETA: 6s - loss: 0.2477 - accuracy: 0.90 - ETA: 6s - loss: 0.2470 - accuracy: 0.90 - ETA: 6s - loss: 0.2477 - accuracy: 0.90 - ETA: 6s - loss: 0.2483 - accuracy: 0.90 - ETA: 6s - loss: 0.2484 - accuracy: 0.90 - ETA: 6s - loss: 0.2484 - accuracy: 0.90 - ETA: 6s - loss: 0.2490 - accuracy: 0.90 - ETA: 6s - loss: 0.2488 - accuracy: 0.90 - ETA: 6s - loss: 0.2489 - accuracy: 0.90 - ETA: 6s - loss: 0.2492 - accuracy: 0.90 - ETA: 6s - loss: 0.2483 - accuracy: 0.90 - ETA: 6s - loss: 0.2479 - accuracy: 0.90 - ETA: 6s - loss: 0.2487 - accuracy: 0.90 - ETA: 6s - loss: 0.2480 - accuracy: 0.90 - ETA: 5s - loss: 0.2482 - accuracy: 0.90 - ETA: 5s - loss: 0.2478 - accuracy: 0.90 - ETA: 5s - loss: 0.2476 - accuracy: 0.90 - ETA: 5s - loss: 0.2475 - accuracy: 0.90 - ETA: 5s - loss: 0.2472 - accuracy: 0.90 - ETA: 5s - loss: 0.2462 - accuracy: 0.90 - ETA: 5s - loss: 0.2466 - accuracy: 0.90 - ETA: 5s - loss: 0.2466 - accuracy: 0.90 - ETA: 5s - loss: 0.2468 - accuracy: 0.90 - ETA: 5s - loss: 0.2471 - accuracy: 0.90 - ETA: 5s - loss: 0.2470 - accuracy: 0.90 - ETA: 5s - loss: 0.2467 - accuracy: 0.90 - ETA: 5s - loss: 0.2454 - accuracy: 0.90 - ETA: 5s - loss: 0.2458 - accuracy: 0.90 - ETA: 5s - loss: 0.2458 - accuracy: 0.90 - ETA: 5s - loss: 0.2453 - accuracy: 0.90 - ETA: 5s - loss: 0.2448 - accuracy: 0.90 - ETA: 4s - loss: 0.2446 - accuracy: 0.90 - ETA: 4s - loss: 0.2443 - accuracy: 0.90 - ETA: 4s - loss: 0.2445 - accuracy: 0.90 - ETA: 4s - loss: 0.2443 - accuracy: 0.90 - ETA: 4s - loss: 0.2447 - accuracy: 0.90 - ETA: 4s - loss: 0.2451 - accuracy: 0.90 - ETA: 4s - loss: 0.2449 - accuracy: 0.90 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 4s - loss: 0.2456 - accuracy: 0.90 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 4s - loss: 0.2453 - accuracy: 0.90 - ETA: 4s - loss: 0.2457 - accuracy: 0.90 - ETA: 4s - loss: 0.2453 - accuracy: 0.90 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 4s - loss: 0.2455 - accuracy: 0.90 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 4s - loss: 0.2458 - accuracy: 0.90 - ETA: 4s - loss: 0.2456 - accuracy: 0.90 - ETA: 4s - loss: 0.2454 - accuracy: 0.90 - ETA: 3s - loss: 0.2455 - accuracy: 0.90 - ETA: 3s - loss: 0.2454 - accuracy: 0.90 - ETA: 3s - loss: 0.2455 - accuracy: 0.90 - ETA: 3s - loss: 0.2456 - accuracy: 0.90 - ETA: 3s - loss: 0.2465 - accuracy: 0.90 - ETA: 3s - loss: 0.2460 - accuracy: 0.90 - ETA: 3s - loss: 0.2464 - accuracy: 0.90 - ETA: 3s - loss: 0.2467 - accuracy: 0.90 - ETA: 3s - loss: 0.2468 - accuracy: 0.90 - ETA: 3s - loss: 0.2465 - accuracy: 0.90 - ETA: 3s - loss: 0.2468 - accuracy: 0.90 - ETA: 3s - loss: 0.2466 - accuracy: 0.90 - ETA: 3s - loss: 0.2467 - accuracy: 0.90 - ETA: 3s - loss: 0.2465 - accuracy: 0.90 - ETA: 3s - loss: 0.2461 - accuracy: 0.90 - ETA: 3s - loss: 0.2457 - accuracy: 0.90 - ETA: 3s - loss: 0.2456 - accuracy: 0.90 - ETA: 2s - loss: 0.2449 - accuracy: 0.90 - ETA: 2s - loss: 0.2448 - accuracy: 0.90 - ETA: 2s - loss: 0.2453 - accuracy: 0.90 - ETA: 2s - loss: 0.2452 - accuracy: 0.90 - ETA: 2s - loss: 0.2450 - accuracy: 0.90 - ETA: 2s - loss: 0.2454 - accuracy: 0.90 - ETA: 2s - loss: 0.2456 - accuracy: 0.90 - ETA: 2s - loss: 0.2457 - accuracy: 0.90 - ETA: 2s - loss: 0.2460 - accuracy: 0.90 - ETA: 2s - loss: 0.2459 - accuracy: 0.90 - ETA: 2s - loss: 0.2462 - accuracy: 0.90 - ETA: 2s - loss: 0.2458 - accuracy: 0.90 - ETA: 2s - loss: 0.2456 - accuracy: 0.90 - ETA: 2s - loss: 0.2458 - accuracy: 0.90 - ETA: 2s - loss: 0.2454 - accuracy: 0.90 - ETA: 2s - loss: 0.2453 - accuracy: 0.90 - ETA: 2s - loss: 0.2453 - accuracy: 0.90 - ETA: 2s - loss: 0.2449 - accuracy: 0.90 - ETA: 2s - loss: 0.2448 - accuracy: 0.90 - ETA: 1s - loss: 0.2443 - accuracy: 0.90 - ETA: 1s - loss: 0.2440 - accuracy: 0.90 - ETA: 1s - loss: 0.2442 - accuracy: 0.90 - ETA: 1s - loss: 0.2439 - accuracy: 0.90 - ETA: 1s - loss: 0.2439 - accuracy: 0.90 - ETA: 1s - loss: 0.2440 - accuracy: 0.90 - ETA: 1s - loss: 0.2441 - accuracy: 0.90 - ETA: 1s - loss: 0.2441 - accuracy: 0.90 - ETA: 1s - loss: 0.2444 - accuracy: 0.90 - ETA: 1s - loss: 0.2445 - accuracy: 0.90 - ETA: 1s - loss: 0.2445 - accuracy: 0.90 - ETA: 1s - loss: 0.2443 - accuracy: 0.90 - ETA: 1s - loss: 0.2443 - accuracy: 0.90 - ETA: 1s - loss: 0.2437 - accuracy: 0.90 - ETA: 1s - loss: 0.2435 - accuracy: 0.90 - ETA: 1s - loss: 0.2438 - accuracy: 0.90 - ETA: 1s - loss: 0.2437 - accuracy: 0.90 - ETA: 1s - loss: 0.2437 - accuracy: 0.90 - ETA: 0s - loss: 0.2437 - accuracy: 0.90 - ETA: 0s - loss: 0.2438 - accuracy: 0.90 - ETA: 0s - loss: 0.2439 - accuracy: 0.90 - ETA: 0s - loss: 0.2439 - accuracy: 0.90 - ETA: 0s - loss: 0.2438 - accuracy: 0.90 - ETA: 0s - loss: 0.2436 - accuracy: 0.90 - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - ETA: 0s - loss: 0.2434 - accuracy: 0.90 - ETA: 0s - loss: 0.2434 - accuracy: 0.90 - ETA: 0s - loss: 0.2431 - accuracy: 0.90 - ETA: 0s - loss: 0.2428 - accuracy: 0.90 - ETA: 0s - loss: 0.2429 - accuracy: 0.90 - ETA: 0s - loss: 0.2426 - accuracy: 0.90 - ETA: 0s - loss: 0.2422 - accuracy: 0.90 - ETA: 0s - loss: 0.2420 - accuracy: 0.90 - ETA: 0s - loss: 0.2419 - accuracy: 0.90 - ETA: 0s - loss: 0.2418 - accuracy: 0.90 - ETA: 0s - loss: 0.2419 - accuracy: 0.90 - 10s 172us/sample - loss: 0.2418 - accuracy: 0.9086 - val_loss: 0.3569 - val_accuracy: 0.8804\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 13s - loss: 0.1952 - accuracy: 0.875 - ETA: 9s - loss: 0.2315 - accuracy: 0.906 - ETA: 9s - loss: 0.2454 - accuracy: 0.90 - ETA: 9s - loss: 0.2338 - accuracy: 0.91 - ETA: 8s - loss: 0.2403 - accuracy: 0.90 - ETA: 8s - loss: 0.2372 - accuracy: 0.90 - ETA: 8s - loss: 0.2395 - accuracy: 0.90 - ETA: 8s - loss: 0.2393 - accuracy: 0.90 - ETA: 8s - loss: 0.2374 - accuracy: 0.90 - ETA: 8s - loss: 0.2383 - accuracy: 0.91 - ETA: 8s - loss: 0.2422 - accuracy: 0.90 - ETA: 8s - loss: 0.2450 - accuracy: 0.90 - ETA: 8s - loss: 0.2442 - accuracy: 0.90 - ETA: 8s - loss: 0.2429 - accuracy: 0.90 - ETA: 8s - loss: 0.2423 - accuracy: 0.90 - ETA: 8s - loss: 0.2407 - accuracy: 0.90 - ETA: 8s - loss: 0.2379 - accuracy: 0.91 - ETA: 8s - loss: 0.2380 - accuracy: 0.91 - ETA: 8s - loss: 0.2382 - accuracy: 0.91 - ETA: 8s - loss: 0.2356 - accuracy: 0.91 - ETA: 8s - loss: 0.2337 - accuracy: 0.91 - ETA: 8s - loss: 0.2331 - accuracy: 0.91 - ETA: 8s - loss: 0.2300 - accuracy: 0.91 - ETA: 8s - loss: 0.2309 - accuracy: 0.91 - ETA: 7s - loss: 0.2307 - accuracy: 0.91 - ETA: 7s - loss: 0.2286 - accuracy: 0.91 - ETA: 7s - loss: 0.2264 - accuracy: 0.91 - ETA: 7s - loss: 0.2244 - accuracy: 0.91 - ETA: 7s - loss: 0.2258 - accuracy: 0.91 - ETA: 7s - loss: 0.2259 - accuracy: 0.91 - ETA: 7s - loss: 0.2259 - accuracy: 0.91 - ETA: 7s - loss: 0.2263 - accuracy: 0.91 - ETA: 7s - loss: 0.2248 - accuracy: 0.91 - ETA: 7s - loss: 0.2263 - accuracy: 0.91 - ETA: 7s - loss: 0.2256 - accuracy: 0.91 - ETA: 7s - loss: 0.2277 - accuracy: 0.91 - ETA: 7s - loss: 0.2275 - accuracy: 0.91 - ETA: 7s - loss: 0.2258 - accuracy: 0.91 - ETA: 7s - loss: 0.2245 - accuracy: 0.91 - ETA: 7s - loss: 0.2243 - accuracy: 0.91 - ETA: 7s - loss: 0.2233 - accuracy: 0.91 - ETA: 7s - loss: 0.2228 - accuracy: 0.91 - ETA: 7s - loss: 0.2229 - accuracy: 0.91 - ETA: 6s - loss: 0.2228 - accuracy: 0.91 - ETA: 6s - loss: 0.2223 - accuracy: 0.91 - ETA: 6s - loss: 0.2222 - accuracy: 0.91 - ETA: 6s - loss: 0.2233 - accuracy: 0.91 - ETA: 6s - loss: 0.2241 - accuracy: 0.91 - ETA: 6s - loss: 0.2242 - accuracy: 0.91 - ETA: 6s - loss: 0.2251 - accuracy: 0.91 - ETA: 6s - loss: 0.2257 - accuracy: 0.91 - ETA: 6s - loss: 0.2258 - accuracy: 0.91 - ETA: 6s - loss: 0.2259 - accuracy: 0.91 - ETA: 6s - loss: 0.2255 - accuracy: 0.91 - ETA: 6s - loss: 0.2256 - accuracy: 0.91 - ETA: 6s - loss: 0.2268 - accuracy: 0.91 - ETA: 6s - loss: 0.2279 - accuracy: 0.91 - ETA: 6s - loss: 0.2284 - accuracy: 0.91 - ETA: 6s - loss: 0.2282 - accuracy: 0.91 - ETA: 6s - loss: 0.2287 - accuracy: 0.91 - ETA: 6s - loss: 0.2290 - accuracy: 0.91 - ETA: 6s - loss: 0.2283 - accuracy: 0.91 - ETA: 6s - loss: 0.2283 - accuracy: 0.91 - ETA: 5s - loss: 0.2276 - accuracy: 0.91 - ETA: 5s - loss: 0.2275 - accuracy: 0.91 - ETA: 5s - loss: 0.2270 - accuracy: 0.91 - ETA: 5s - loss: 0.2269 - accuracy: 0.91 - ETA: 5s - loss: 0.2271 - accuracy: 0.91 - ETA: 5s - loss: 0.2276 - accuracy: 0.91 - ETA: 5s - loss: 0.2272 - accuracy: 0.91 - ETA: 5s - loss: 0.2273 - accuracy: 0.91 - ETA: 5s - loss: 0.2276 - accuracy: 0.91 - ETA: 5s - loss: 0.2273 - accuracy: 0.91 - ETA: 5s - loss: 0.2267 - accuracy: 0.91 - ETA: 5s - loss: 0.2269 - accuracy: 0.91 - ETA: 5s - loss: 0.2277 - accuracy: 0.91 - ETA: 5s - loss: 0.2276 - accuracy: 0.91 - ETA: 5s - loss: 0.2277 - accuracy: 0.91 - ETA: 5s - loss: 0.2271 - accuracy: 0.91 - ETA: 5s - loss: 0.2270 - accuracy: 0.91 - ETA: 5s - loss: 0.2271 - accuracy: 0.91 - ETA: 5s - loss: 0.2274 - accuracy: 0.91 - ETA: 5s - loss: 0.2273 - accuracy: 0.91 - ETA: 5s - loss: 0.2271 - accuracy: 0.91 - ETA: 4s - loss: 0.2272 - accuracy: 0.91 - ETA: 4s - loss: 0.2268 - accuracy: 0.91 - ETA: 4s - loss: 0.2268 - accuracy: 0.91 - ETA: 4s - loss: 0.2264 - accuracy: 0.91 - ETA: 4s - loss: 0.2273 - accuracy: 0.91 - ETA: 4s - loss: 0.2273 - accuracy: 0.91 - ETA: 4s - loss: 0.2273 - accuracy: 0.91 - ETA: 4s - loss: 0.2272 - accuracy: 0.91 - ETA: 4s - loss: 0.2277 - accuracy: 0.91 - ETA: 4s - loss: 0.2276 - accuracy: 0.91 - ETA: 4s - loss: 0.2277 - accuracy: 0.91 - ETA: 4s - loss: 0.2273 - accuracy: 0.91 - ETA: 4s - loss: 0.2278 - accuracy: 0.91 - ETA: 4s - loss: 0.2290 - accuracy: 0.91 - ETA: 4s - loss: 0.2288 - accuracy: 0.91 - ETA: 4s - loss: 0.2289 - accuracy: 0.91 - ETA: 4s - loss: 0.2290 - accuracy: 0.91 - ETA: 4s - loss: 0.2291 - accuracy: 0.91 - ETA: 3s - loss: 0.2289 - accuracy: 0.91 - ETA: 3s - loss: 0.2288 - accuracy: 0.91 - ETA: 3s - loss: 0.2285 - accuracy: 0.91 - ETA: 3s - loss: 0.2287 - accuracy: 0.91 - ETA: 3s - loss: 0.2292 - accuracy: 0.91 - ETA: 3s - loss: 0.2293 - accuracy: 0.91 - ETA: 3s - loss: 0.2294 - accuracy: 0.91 - ETA: 3s - loss: 0.2292 - accuracy: 0.91 - ETA: 3s - loss: 0.2294 - accuracy: 0.91 - ETA: 3s - loss: 0.2297 - accuracy: 0.91 - ETA: 3s - loss: 0.2298 - accuracy: 0.91 - ETA: 3s - loss: 0.2299 - accuracy: 0.91 - ETA: 3s - loss: 0.2299 - accuracy: 0.91 - ETA: 3s - loss: 0.2297 - accuracy: 0.91 - ETA: 3s - loss: 0.2293 - accuracy: 0.91 - ETA: 3s - loss: 0.2296 - accuracy: 0.91 - ETA: 3s - loss: 0.2296 - accuracy: 0.91 - ETA: 3s - loss: 0.2298 - accuracy: 0.91 - ETA: 3s - loss: 0.2296 - accuracy: 0.91 - ETA: 3s - loss: 0.2300 - accuracy: 0.91 - ETA: 3s - loss: 0.2303 - accuracy: 0.91 - ETA: 3s - loss: 0.2303 - accuracy: 0.91 - ETA: 3s - loss: 0.2302 - accuracy: 0.91 - ETA: 2s - loss: 0.2301 - accuracy: 0.91 - ETA: 2s - loss: 0.2301 - accuracy: 0.91 - ETA: 2s - loss: 0.2301 - accuracy: 0.91 - ETA: 2s - loss: 0.2300 - accuracy: 0.91 - ETA: 2s - loss: 0.2299 - accuracy: 0.91 - ETA: 2s - loss: 0.2299 - accuracy: 0.91 - ETA: 2s - loss: 0.2303 - accuracy: 0.91 - ETA: 2s - loss: 0.2305 - accuracy: 0.91 - ETA: 2s - loss: 0.2306 - accuracy: 0.91 - ETA: 2s - loss: 0.2303 - accuracy: 0.91 - ETA: 2s - loss: 0.2302 - accuracy: 0.91 - ETA: 2s - loss: 0.2301 - accuracy: 0.91 - ETA: 2s - loss: 0.2300 - accuracy: 0.91 - ETA: 2s - loss: 0.2299 - accuracy: 0.91 - ETA: 2s - loss: 0.2297 - accuracy: 0.91 - ETA: 2s - loss: 0.2296 - accuracy: 0.91 - ETA: 2s - loss: 0.2291 - accuracy: 0.91 - ETA: 2s - loss: 0.2292 - accuracy: 0.91 - ETA: 1s - loss: 0.2289 - accuracy: 0.91 - ETA: 1s - loss: 0.2290 - accuracy: 0.91 - ETA: 1s - loss: 0.2293 - accuracy: 0.91 - ETA: 1s - loss: 0.2291 - accuracy: 0.91 - ETA: 1s - loss: 0.2297 - accuracy: 0.91 - ETA: 1s - loss: 0.2302 - accuracy: 0.91 - ETA: 1s - loss: 0.2303 - accuracy: 0.91 - ETA: 1s - loss: 0.2305 - accuracy: 0.91 - ETA: 1s - loss: 0.2305 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2311 - accuracy: 0.91 - ETA: 1s - loss: 0.2311 - accuracy: 0.91 - ETA: 1s - loss: 0.2311 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2313 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2315 - accuracy: 0.91 - ETA: 1s - loss: 0.2317 - accuracy: 0.91 - ETA: 0s - loss: 0.2319 - accuracy: 0.91 - ETA: 0s - loss: 0.2320 - accuracy: 0.91 - ETA: 0s - loss: 0.2322 - accuracy: 0.91 - ETA: 0s - loss: 0.2321 - accuracy: 0.91 - ETA: 0s - loss: 0.2319 - accuracy: 0.91 - ETA: 0s - loss: 0.2320 - accuracy: 0.91 - ETA: 0s - loss: 0.2321 - accuracy: 0.91 - ETA: 0s - loss: 0.2322 - accuracy: 0.91 - ETA: 0s - loss: 0.2323 - accuracy: 0.91 - ETA: 0s - loss: 0.2325 - accuracy: 0.91 - ETA: 0s - loss: 0.2324 - accuracy: 0.91 - ETA: 0s - loss: 0.2323 - accuracy: 0.91 - ETA: 0s - loss: 0.2324 - accuracy: 0.91 - ETA: 0s - loss: 0.2325 - accuracy: 0.91 - ETA: 0s - loss: 0.2323 - accuracy: 0.91 - ETA: 0s - loss: 0.2324 - accuracy: 0.91 - ETA: 0s - loss: 0.2326 - accuracy: 0.91 - ETA: 0s - loss: 0.2328 - accuracy: 0.91 - 11s 175us/sample - loss: 0.2328 - accuracy: 0.9135 - val_loss: 0.3491 - val_accuracy: 0.8787\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54592/60000 [==========================>...] - ETA: 14s - loss: 0.1411 - accuracy: 0.968 - ETA: 9s - loss: 0.2554 - accuracy: 0.906 - ETA: 8s - loss: 0.2569 - accuracy: 0.90 - ETA: 8s - loss: 0.2416 - accuracy: 0.90 - ETA: 8s - loss: 0.2240 - accuracy: 0.91 - ETA: 8s - loss: 0.2295 - accuracy: 0.91 - ETA: 8s - loss: 0.2257 - accuracy: 0.91 - ETA: 8s - loss: 0.2148 - accuracy: 0.91 - ETA: 8s - loss: 0.2214 - accuracy: 0.91 - ETA: 8s - loss: 0.2259 - accuracy: 0.91 - ETA: 8s - loss: 0.2264 - accuracy: 0.91 - ETA: 8s - loss: 0.2254 - accuracy: 0.91 - ETA: 8s - loss: 0.2270 - accuracy: 0.91 - ETA: 8s - loss: 0.2224 - accuracy: 0.91 - ETA: 8s - loss: 0.2217 - accuracy: 0.91 - ETA: 8s - loss: 0.2248 - accuracy: 0.91 - ETA: 8s - loss: 0.2258 - accuracy: 0.91 - ETA: 8s - loss: 0.2267 - accuracy: 0.91 - ETA: 8s - loss: 0.2273 - accuracy: 0.91 - ETA: 8s - loss: 0.2278 - accuracy: 0.91 - ETA: 8s - loss: 0.2252 - accuracy: 0.91 - ETA: 8s - loss: 0.2245 - accuracy: 0.91 - ETA: 8s - loss: 0.2236 - accuracy: 0.91 - ETA: 8s - loss: 0.2225 - accuracy: 0.91 - ETA: 8s - loss: 0.2203 - accuracy: 0.91 - ETA: 8s - loss: 0.2211 - accuracy: 0.91 - ETA: 8s - loss: 0.2204 - accuracy: 0.91 - ETA: 9s - loss: 0.2204 - accuracy: 0.91 - ETA: 9s - loss: 0.2211 - accuracy: 0.91 - ETA: 9s - loss: 0.2229 - accuracy: 0.91 - ETA: 9s - loss: 0.2231 - accuracy: 0.91 - ETA: 9s - loss: 0.2215 - accuracy: 0.91 - ETA: 9s - loss: 0.2189 - accuracy: 0.91 - ETA: 9s - loss: 0.2190 - accuracy: 0.91 - ETA: 8s - loss: 0.2162 - accuracy: 0.91 - ETA: 8s - loss: 0.2168 - accuracy: 0.91 - ETA: 8s - loss: 0.2178 - accuracy: 0.91 - ETA: 8s - loss: 0.2176 - accuracy: 0.91 - ETA: 8s - loss: 0.2173 - accuracy: 0.91 - ETA: 8s - loss: 0.2162 - accuracy: 0.91 - ETA: 8s - loss: 0.2169 - accuracy: 0.91 - ETA: 8s - loss: 0.2178 - accuracy: 0.91 - ETA: 8s - loss: 0.2183 - accuracy: 0.91 - ETA: 8s - loss: 0.2196 - accuracy: 0.91 - ETA: 8s - loss: 0.2216 - accuracy: 0.91 - ETA: 8s - loss: 0.2218 - accuracy: 0.91 - ETA: 7s - loss: 0.2228 - accuracy: 0.91 - ETA: 7s - loss: 0.2218 - accuracy: 0.91 - ETA: 7s - loss: 0.2205 - accuracy: 0.91 - ETA: 7s - loss: 0.2202 - accuracy: 0.91 - ETA: 7s - loss: 0.2200 - accuracy: 0.91 - ETA: 7s - loss: 0.2199 - accuracy: 0.91 - ETA: 7s - loss: 0.2196 - accuracy: 0.91 - ETA: 7s - loss: 0.2191 - accuracy: 0.91 - ETA: 7s - loss: 0.2187 - accuracy: 0.91 - ETA: 7s - loss: 0.2187 - accuracy: 0.91 - ETA: 7s - loss: 0.2185 - accuracy: 0.91 - ETA: 7s - loss: 0.2178 - accuracy: 0.91 - ETA: 7s - loss: 0.2168 - accuracy: 0.91 - ETA: 7s - loss: 0.2168 - accuracy: 0.91 - ETA: 7s - loss: 0.2166 - accuracy: 0.91 - ETA: 7s - loss: 0.2168 - accuracy: 0.91 - ETA: 7s - loss: 0.2157 - accuracy: 0.91 - ETA: 7s - loss: 0.2168 - accuracy: 0.91 - ETA: 7s - loss: 0.2166 - accuracy: 0.91 - ETA: 7s - loss: 0.2173 - accuracy: 0.91 - ETA: 7s - loss: 0.2177 - accuracy: 0.91 - ETA: 7s - loss: 0.2181 - accuracy: 0.91 - ETA: 6s - loss: 0.2186 - accuracy: 0.91 - ETA: 6s - loss: 0.2186 - accuracy: 0.91 - ETA: 6s - loss: 0.2187 - accuracy: 0.91 - ETA: 6s - loss: 0.2189 - accuracy: 0.91 - ETA: 6s - loss: 0.2189 - accuracy: 0.91 - ETA: 6s - loss: 0.2182 - accuracy: 0.91 - ETA: 6s - loss: 0.2182 - accuracy: 0.91 - ETA: 6s - loss: 0.2182 - accuracy: 0.91 - ETA: 6s - loss: 0.2180 - accuracy: 0.91 - ETA: 6s - loss: 0.2180 - accuracy: 0.91 - ETA: 6s - loss: 0.2182 - accuracy: 0.91 - ETA: 6s - loss: 0.2178 - accuracy: 0.91 - ETA: 6s - loss: 0.2178 - accuracy: 0.91 - ETA: 6s - loss: 0.2186 - accuracy: 0.91 - ETA: 6s - loss: 0.2180 - accuracy: 0.91 - ETA: 6s - loss: 0.2190 - accuracy: 0.91 - ETA: 6s - loss: 0.2191 - accuracy: 0.91 - ETA: 6s - loss: 0.2201 - accuracy: 0.91 - ETA: 6s - loss: 0.2203 - accuracy: 0.91 - ETA: 6s - loss: 0.2207 - accuracy: 0.91 - ETA: 6s - loss: 0.2204 - accuracy: 0.91 - ETA: 6s - loss: 0.2201 - accuracy: 0.91 - ETA: 6s - loss: 0.2200 - accuracy: 0.91 - ETA: 6s - loss: 0.2211 - accuracy: 0.91 - ETA: 6s - loss: 0.2210 - accuracy: 0.91 - ETA: 6s - loss: 0.2205 - accuracy: 0.91 - ETA: 6s - loss: 0.2206 - accuracy: 0.91 - ETA: 6s - loss: 0.2202 - accuracy: 0.91 - ETA: 6s - loss: 0.2202 - accuracy: 0.91 - ETA: 6s - loss: 0.2199 - accuracy: 0.91 - ETA: 6s - loss: 0.2196 - accuracy: 0.91 - ETA: 6s - loss: 0.2199 - accuracy: 0.91 - ETA: 6s - loss: 0.2194 - accuracy: 0.91 - ETA: 5s - loss: 0.2193 - accuracy: 0.91 - ETA: 5s - loss: 0.2197 - accuracy: 0.91 - ETA: 5s - loss: 0.2200 - accuracy: 0.91 - ETA: 5s - loss: 0.2201 - accuracy: 0.91 - ETA: 5s - loss: 0.2205 - accuracy: 0.91 - ETA: 5s - loss: 0.2210 - accuracy: 0.91 - ETA: 5s - loss: 0.2213 - accuracy: 0.91 - ETA: 5s - loss: 0.2215 - accuracy: 0.91 - ETA: 5s - loss: 0.2214 - accuracy: 0.91 - ETA: 5s - loss: 0.2212 - accuracy: 0.91 - ETA: 5s - loss: 0.2211 - accuracy: 0.91 - ETA: 5s - loss: 0.2212 - accuracy: 0.91 - ETA: 5s - loss: 0.2210 - accuracy: 0.91 - ETA: 5s - loss: 0.2207 - accuracy: 0.91 - ETA: 5s - loss: 0.2209 - accuracy: 0.91 - ETA: 5s - loss: 0.2209 - accuracy: 0.91 - ETA: 5s - loss: 0.2212 - accuracy: 0.91 - ETA: 5s - loss: 0.2208 - accuracy: 0.91 - ETA: 5s - loss: 0.2205 - accuracy: 0.91 - ETA: 5s - loss: 0.2206 - accuracy: 0.91 - ETA: 5s - loss: 0.2209 - accuracy: 0.91 - ETA: 5s - loss: 0.2212 - accuracy: 0.91 - ETA: 5s - loss: 0.2210 - accuracy: 0.91 - ETA: 5s - loss: 0.2211 - accuracy: 0.91 - ETA: 5s - loss: 0.2207 - accuracy: 0.91 - ETA: 5s - loss: 0.2205 - accuracy: 0.91 - ETA: 5s - loss: 0.2206 - accuracy: 0.91 - ETA: 5s - loss: 0.2209 - accuracy: 0.91 - ETA: 4s - loss: 0.2207 - accuracy: 0.91 - ETA: 4s - loss: 0.2207 - accuracy: 0.91 - ETA: 4s - loss: 0.2208 - accuracy: 0.91 - ETA: 4s - loss: 0.2208 - accuracy: 0.91 - ETA: 4s - loss: 0.2208 - accuracy: 0.91 - ETA: 4s - loss: 0.2209 - accuracy: 0.91 - ETA: 4s - loss: 0.2206 - accuracy: 0.91 - ETA: 4s - loss: 0.2208 - accuracy: 0.91 - ETA: 4s - loss: 0.2213 - accuracy: 0.91 - ETA: 4s - loss: 0.2212 - accuracy: 0.91 - ETA: 4s - loss: 0.2212 - accuracy: 0.91 - ETA: 4s - loss: 0.2209 - accuracy: 0.91 - ETA: 4s - loss: 0.2207 - accuracy: 0.91 - ETA: 4s - loss: 0.2202 - accuracy: 0.91 - ETA: 4s - loss: 0.2204 - accuracy: 0.91 - ETA: 4s - loss: 0.2199 - accuracy: 0.91 - ETA: 4s - loss: 0.2205 - accuracy: 0.91 - ETA: 4s - loss: 0.2203 - accuracy: 0.91 - ETA: 3s - loss: 0.2204 - accuracy: 0.91 - ETA: 3s - loss: 0.2206 - accuracy: 0.91 - ETA: 3s - loss: 0.2203 - accuracy: 0.91 - ETA: 3s - loss: 0.2207 - accuracy: 0.91 - ETA: 3s - loss: 0.2204 - accuracy: 0.91 - ETA: 3s - loss: 0.2203 - accuracy: 0.91 - ETA: 3s - loss: 0.2210 - accuracy: 0.91 - ETA: 3s - loss: 0.2207 - accuracy: 0.91 - ETA: 3s - loss: 0.2204 - accuracy: 0.91 - ETA: 3s - loss: 0.2202 - accuracy: 0.91 - ETA: 3s - loss: 0.2204 - accuracy: 0.91 - ETA: 3s - loss: 0.2202 - accuracy: 0.91 - ETA: 3s - loss: 0.2205 - accuracy: 0.91 - ETA: 3s - loss: 0.2201 - accuracy: 0.91 - ETA: 2s - loss: 0.2198 - accuracy: 0.91 - ETA: 2s - loss: 0.2197 - accuracy: 0.91 - ETA: 2s - loss: 0.2196 - accuracy: 0.91 - ETA: 2s - loss: 0.2200 - accuracy: 0.91 - ETA: 2s - loss: 0.2198 - accuracy: 0.91 - ETA: 2s - loss: 0.2196 - accuracy: 0.91 - ETA: 2s - loss: 0.2200 - accuracy: 0.91 - ETA: 2s - loss: 0.2200 - accuracy: 0.91 - ETA: 2s - loss: 0.2202 - accuracy: 0.91 - ETA: 2s - loss: 0.2202 - accuracy: 0.91 - ETA: 2s - loss: 0.2201 - accuracy: 0.91 - ETA: 2s - loss: 0.2200 - accuracy: 0.91 - ETA: 2s - loss: 0.2200 - accuracy: 0.91 - ETA: 2s - loss: 0.2201 - accuracy: 0.91 - ETA: 2s - loss: 0.2202 - accuracy: 0.91 - ETA: 2s - loss: 0.2202 - accuracy: 0.91 - ETA: 1s - loss: 0.2202 - accuracy: 0.91 - ETA: 1s - loss: 0.2206 - accuracy: 0.91 - ETA: 1s - loss: 0.2205 - accuracy: 0.91 - ETA: 1s - loss: 0.2206 - accuracy: 0.91 - ETA: 1s - loss: 0.2207 - accuracy: 0.91 - ETA: 1s - loss: 0.2207 - accuracy: 0.91 - ETA: 1s - loss: 0.2208 - accuracy: 0.91 - ETA: 1s - loss: 0.2211 - accuracy: 0.91 - ETA: 1s - loss: 0.2208 - accuracy: 0.91 - ETA: 1s - loss: 0.2205 - accuracy: 0.91 - ETA: 1s - loss: 0.2206 - accuracy: 0.91 - ETA: 1s - loss: 0.2206 - accuracy: 0.91 - ETA: 1s - loss: 0.2210 - accuracy: 0.91 - ETA: 1s - loss: 0.2209 - accuracy: 0.91 - ETA: 1s - loss: 0.2208 - accuracy: 0.91 - ETA: 1s - loss: 0.2208 - accuracy: 0.91 - ETA: 1s - loss: 0.2206 - accuracy: 0.9156"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.91 - ETA: 0s - loss: 0.2205 - accuracy: 0.91 - ETA: 0s - loss: 0.2203 - accuracy: 0.91 - ETA: 0s - loss: 0.2207 - accuracy: 0.91 - ETA: 0s - loss: 0.2206 - accuracy: 0.91 - ETA: 0s - loss: 0.2206 - accuracy: 0.91 - ETA: 0s - loss: 0.2207 - accuracy: 0.91 - ETA: 0s - loss: 0.2207 - accuracy: 0.91 - ETA: 0s - loss: 0.2209 - accuracy: 0.91 - ETA: 0s - loss: 0.2210 - accuracy: 0.91 - ETA: 0s - loss: 0.2213 - accuracy: 0.91 - ETA: 0s - loss: 0.2212 - accuracy: 0.91 - ETA: 0s - loss: 0.2211 - accuracy: 0.91 - ETA: 0s - loss: 0.2214 - accuracy: 0.91 - ETA: 0s - loss: 0.2216 - accuracy: 0.91 - ETA: 0s - loss: 0.2218 - accuracy: 0.91 - ETA: 0s - loss: 0.2217 - accuracy: 0.91 - ETA: 0s - loss: 0.2218 - accuracy: 0.91 - ETA: 0s - loss: 0.2220 - accuracy: 0.91 - ETA: 0s - loss: 0.2219 - accuracy: 0.91 - ETA: 0s - loss: 0.2217 - accuracy: 0.91 - ETA: 0s - loss: 0.2216 - accuracy: 0.91 - ETA: 0s - loss: 0.2217 - accuracy: 0.91 - ETA: 0s - loss: 0.2218 - accuracy: 0.91 - ETA: 0s - loss: 0.2217 - accuracy: 0.91 - 13s 214us/sample - loss: 0.2218 - accuracy: 0.9156 - val_loss: 0.3318 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e881dbd68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQRpPHZsz-eC"
   },
   "source": [
    "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite = True` argument while instantiating the tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKwLOzKpFGAj"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to use the Keras Tuner to tune hyperparameters for a model. To learn more about the Keras Tuner, check out these additional resources:\n",
    "\n",
    "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
    "* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
    "\n",
    "Also check out the [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune your model hyperparameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "keras_tuner.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
